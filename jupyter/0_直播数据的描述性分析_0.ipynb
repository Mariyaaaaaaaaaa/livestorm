{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b1bbfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import re\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# 指定字体\n",
    "font_path = \"C:/Windows/Fonts/simsun.ttc\"  # SimSun字体路径\n",
    "font_prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [font_prop.get_name()]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False  # 解决负号显示问题\n",
    "plt.rcParams[\"font.size\"] = 10.5  # 设置五号字体大小\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d118920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/info.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/info.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/info.xlsx\",\n",
    "            \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/info.xlsx\"\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0ddc6",
   "metadata": {},
   "source": [
    "# 删除非带货主播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c458d070",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"D:/研究生/毕业论文/数据/主播数据/livelinks_1000(2024.03.16-2024.04.14).csv\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/livelinks_500-1000(2024.03.16-2024.04.14).csv\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/livelinks_100-500(2024.03.16-2024.04.14).csv\",\n",
    "            \"D:/研究生/毕业论文/数据/主播数据/livelinks_10-100(2024.03.16-2024.04.14).csv\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d3eccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_csv('D:/研究生/毕业论文/数据/主播数据/livelinks_10-100(2024.03.16-2024.04.14).csv', encoding='gbk')\n",
    "# 筛选is_take_product为FALSE的行。gbk读取为布尔值，而不是字符串。\n",
    "filtered_df = df[df['is_take_product'] == False]\n",
    "# 获取要删除的room_id列表\n",
    "room_ids_to_delete = filtered_df['room_id']\n",
    "room_ids_to_delete = room_ids_to_delete.str.replace('\\t', '')\n",
    "data_folder = 'D:/研究生/毕业论文/数据/主播数据/meichangzhibodata_10-100(2024.03.16-2024.04.14)'\n",
    "# 遍历文件夹中的文件\n",
    "for filename in os.listdir(data_folder):\n",
    "    # 提取文件名的前缀部分（去掉文件扩展名）\n",
    "    file_prefix = os.path.splitext(filename)[0]  # 获取不含扩展名的文件名前缀\n",
    "\n",
    "    # 检查提取的文件前缀是否在room_ids_to_delete中\n",
    "    if file_prefix in room_ids_to_delete.values:\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Skipped file: {filename} (room_id not in list)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7a12c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d687a93a",
   "metadata": {},
   "source": [
    "1135个主播，32413条直播"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa0ad6",
   "metadata": {},
   "source": [
    "# 一个月内的频数分布统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd1933c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空DataFrame用于存储所有数据\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "# 循环读取每个文件并合并数据\n",
    "# 假设文件名中包含等级信息，从文件路径中提取等级\n",
    "# for file_path in file_paths:\n",
    "#     if '10-100' in file_path:\n",
    "#         level = 'Level 4'\n",
    "#     elif '100-500' in file_path:\n",
    "#         level = 'Level 3'\n",
    "#     elif '500-1000' in file_path:\n",
    "#         level = 'Level 2'\n",
    "#     elif '1000' in file_path:\n",
    "#         level = 'Level 1'\n",
    "#     else:\n",
    "#         level = 'Unknown'  # 处理未知等级的文件\n",
    "# 循环读取每个文件并合并数据\n",
    "# 假设文件名中包含等级信息，从文件路径中提取等级\n",
    "for file_path in file_paths:\n",
    "    if '10-100' in file_path:\n",
    "        level = '3'\n",
    "    elif '100-500' in file_path:\n",
    "        level = '2'\n",
    "    elif '500-1000' in file_path:\n",
    "        level = '1'\n",
    "    elif '1000' in file_path:\n",
    "        level = '1'\n",
    "    else:\n",
    "        level = 'Unknown'  # 处理未知等级的文件\n",
    "    # 读取xlsx文件\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # 添加等级列\n",
    "    df['level'] = level\n",
    "    \n",
    "    # 合并数据\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "# 将 begin_time 和 room_finish_time 列的时间戳转换为 pandas 的日期时间格式\n",
    "df_all['begin_time'] = pd.to_datetime(df_all['begin_time'], unit='s')\n",
    "df_all['room_finish_time'] = pd.to_datetime(df_all['room_finish_time'], unit='s')\n",
    "\n",
    "# 将日期时间列的时区从 UTC 转换为北京时间\n",
    "df_all['begin_time'] = df_all['begin_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "df_all['room_finish_time'] = df_all['room_finish_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 提取日期作为新的列\n",
    "df_all['date'] = df_all['begin_time'].dt.date\n",
    "\n",
    "# 按照日期和等级等特征进行分组统计\n",
    "result = df_all.groupby(['date', 'level']).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65a623b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制图表\n",
    "plt.figure(figsize=(8, 6), dpi=400)  # 设置图表尺寸和分辨率\n",
    "sns.lineplot(data=result, markers=True, dashes=False)\n",
    "# plt.title('每日直播间频率分布（按主播等级划分）', fontproperties=font_prop)\n",
    "plt.xlabel('日期', fontweight='bold', fontproperties=font_prop)\n",
    "plt.ylabel('频率', fontweight='bold', fontproperties=font_prop)\n",
    "plt.xticks(rotation=45)\n",
    "legend = plt.legend(title='主播等级', fontsize=10.5, loc='best', prop={'family': 'SimSun'})\n",
    "\n",
    "# 使用 set_font_properties 方法来设置图例标题的字体\n",
    "legend.get_title().set_font_properties(font_prop)\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图为PDF文件\n",
    "plt.savefig('D:/研究生/毕业论文/草稿/图片/date_level.png')\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5978ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, axes = plt.subplots(3, 1, figsize=(8, 6), dpi=200)\n",
    "\n",
    "# 将二维数组展平以便迭代\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 循环绘制每列数据的子图\n",
    "for i, column in enumerate(result.columns):\n",
    "    sns.lineplot(data=result[column], ax=axes[i], marker='o', dashes=False)\n",
    "    axes[i].set_title(f'{column} Frequency by Date')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].legend([column], loc='upper right')\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图表\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521756a8",
   "metadata": {},
   "source": [
    "在一个月内，头部主播每天的直播很稳定，非头部主播每天的直播很不稳定。但是单独看每类主播都不稳定，可能是因为非头部的基数太大造成变化幅度很大，因此放在一张图的时候，会显得头部主播的每天直播就很稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6910e",
   "metadata": {},
   "source": [
    "# 一周内的频数分布统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b52732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 df_all 是已经处理好的数据框，包含了 begin_time、room_finish_time、level 等列\n",
    "# 请确保 df_all 包含这些列，并已将日期时间转换为 pandas 的日期时间格式，并添加了 level 列\n",
    "\n",
    "# 创建日期对应的星期几映射\n",
    "day_of_week_map = {\n",
    "    0: '星期一',\n",
    "    1: '星期二',\n",
    "    2: '星期三',\n",
    "    3: '星期四',\n",
    "    4: '星期五',\n",
    "    5: '星期六',\n",
    "    6: '星期日'\n",
    "}\n",
    "\n",
    "# 获取日期对应的星期几函数\n",
    "def get_day_of_week(date):\n",
    "    return day_of_week_map[date.dayofweek]\n",
    "\n",
    "# 添加星期几列\n",
    "df_all['day_of_week'] = df_all['begin_time'].apply(get_day_of_week)\n",
    "\n",
    "# 按照星期几和等级等特征进行分组统计\n",
    "result = df_all.groupby(['day_of_week', 'level']).size().unstack(fill_value=0)\n",
    "\n",
    "# 定义按照顺序排序的星期几列表\n",
    "week_order = ['星期一', '星期二', '星期三', '星期四', '星期五', '星期六', '星期日']\n",
    "\n",
    "# 按照指定顺序重新排列索引\n",
    "result = result.reindex(index=week_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c76161fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据\n",
    "weekdays = ['星期一', '星期二', '星期三', '星期四', '星期五', '星期六', '星期日']\n",
    "levels = ['1', '2', '3']\n",
    "data = result.loc[:, levels]\n",
    "\n",
    "# 自定义颜色列表\n",
    "colors = [(144/255, 201/255, 231/255), (33/255, 158/255, 188/255), (19/255, 103/255, 131/255)]\n",
    "\n",
    "# 创建画布和子图\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 6), dpi=400)\n",
    "\n",
    "# 遍历每个子图位置以及对应的水平索引和垂直索引\n",
    "for i, (level, ax) in enumerate(zip(levels, axs.flat)):\n",
    "    # 绘制柱形图\n",
    "    ax.bar(np.arange(len(weekdays)), data[level], color=colors[i])\n",
    "    \n",
    "    # 设置标题和坐标轴标签\n",
    "    ax.set_title(f'主播等级 {i+1}', fontweight='bold', fontproperties=font_prop)\n",
    "    ax.set_ylabel('频率', fontweight='bold', fontproperties=font_prop)\n",
    "    \n",
    "    # 只在最后一个子图上设置 x 轴标签\n",
    "    if i == len(levels) - 1:\n",
    "        ax.set_xticks(np.arange(len(weekdays)))\n",
    "        ax.set_xticklabels(weekdays, fontproperties=font_prop)\n",
    "        ax.set_xlabel('星期', fontproperties=font_prop)\n",
    "    else:\n",
    "        ax.set_xticks([])  # 移除其它子图的 x 轴刻度\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图为PDF文件\n",
    "plt.savefig('D:/研究生/毕业论文/草稿/图片/weekday_level.png')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177eedd3",
   "metadata": {},
   "source": [
    "可以看出，周末和非周末之间是非常不一样的直播频数，不仅是头部，还是非头部。因此需要分开讨论两种情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ec907",
   "metadata": {},
   "source": [
    "# 一天内的频数分布统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac218fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义时间段划分函数\n",
    "def get_time_period(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return '上午'\n",
    "    elif 12 <= hour < 18:\n",
    "        return '下午'\n",
    "    elif 18 <= hour < 24:\n",
    "        return '晚上'\n",
    "    else:\n",
    "        return '凌晨'\n",
    "\n",
    "# 创建一个空的 DataFrame 用于存储时间段统计结果\n",
    "time_period_counts = pd.DataFrame()\n",
    "\n",
    "# 遍历每个文件中的数据\n",
    "for index, row in df_all.iterrows():\n",
    "    # 获取开始时间的小时并根据小时获取时间段\n",
    "    begin_hour = row['begin_time'].hour\n",
    "    time_period = get_time_period(begin_hour)\n",
    "    \n",
    "    # 将时间段添加到原始数据中的新列 time_period 中\n",
    "    df_all.loc[index, 'time_period'] = time_period\n",
    "\n",
    "# 按照时间段和等级分组统计\n",
    "result_time_periods = df_all.groupby(['time_period', 'level']).size().unstack(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a6b978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义按照顺序排序的星期几列表\n",
    "day_order = ['凌晨', '上午', '下午', '晚上']\n",
    "\n",
    "# 按照指定顺序重新排列索引\n",
    "result_time_periods = result_time_periods.reindex(index=day_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ffc7782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义颜色\n",
    "colors = [(144/255, 201/255, 231/255), (33/255, 158/255, 188/255), (19/255, 103/255, 131/255)]\n",
    "\n",
    "# 定义时间段顺序（确保和 result_time_periods.index 一致）\n",
    "day_order = ['凌晨', '上午', '下午', '晚上']  # 你需要根据实际时间段顺序修改此列表\n",
    "\n",
    "# 创建 3x1 的子图网格\n",
    "fig, axs = plt.subplots(3, 1, figsize=(8, 6), dpi=400)\n",
    "\n",
    "# 在每个子图中绘制数据\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    # 获取对应的时间段数据\n",
    "    time_period_data = result_time_periods.iloc[:, i]\n",
    "    \n",
    "    # 绘制柱形图\n",
    "    ax.bar(time_period_data.index, time_period_data, color=colors[i])\n",
    "    \n",
    "    # 设置子图标题\n",
    "    ax.set_title(f'主播等级 {i+1}', fontweight='bold', fontproperties=font_prop)\n",
    "    \n",
    "    # 设置子图坐标轴标签\n",
    "    ax.set_ylabel('频率', fontweight='bold', fontproperties=font_prop)\n",
    "    \n",
    "    # 设置 x 轴刻度和标签\n",
    "    if i == len(axs.flat) - 1:  # 仅在最后一个子图设置 x 轴刻度和标签\n",
    "        ax.set_xticks(np.arange(len(day_order)))\n",
    "        ax.set_xticklabels(day_order, fontproperties=font_prop)\n",
    "        ax.set_xlabel('时间段', fontproperties=font_prop)\n",
    "    else:\n",
    "        ax.set_xticks([])  # 移除其他子图的 x 轴刻度和标签\n",
    "\n",
    "# 调整子图布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图为PDF文件\n",
    "plt.savefig('D:/研究生/毕业论文/草稿/图片/period_level.png')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090768f",
   "metadata": {},
   "source": [
    "可以看出，大部分的直播集中在非睡眠时间，同时直播间的热度呈现逐渐上升的趋势。但是不同等级的主播重点直播时间段有所不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b5d1b",
   "metadata": {},
   "source": [
    "# 每小时内的频数分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "471e6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加 hour 列，根据 begin_time 提取小时\n",
    "df_all['hour'] = df_all['begin_time'].dt.hour\n",
    "\n",
    "# 按照小时和等级分组统计\n",
    "result_hours = df_all.groupby(['hour', 'level']).size().unstack(fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f7f2636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置画布和子图数量\n",
    "num_levels = result_hours.shape[1]\n",
    "fig, axs = plt.subplots(num_levels, 1, figsize=(8, 6), dpi=400)\n",
    "\n",
    "# 如果只有一个等级时，axs 不是列表，需要转换为列表\n",
    "if num_levels == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "# 遍历每个等级并绘制在对应的子图上\n",
    "for i, level in enumerate(result_hours.columns):\n",
    "    axs[i].plot(result_hours.index, result_hours[level], marker='o')\n",
    "    axs[i].set_title(f'主播等级 {level}', fontproperties=font_prop)  # 使用中文字体显示标题\n",
    "    axs[i].set_ylabel('频数', fontproperties=font_prop)\n",
    "    # axs[i].grid(True)\n",
    "\n",
    "# 设置公共的 x 轴标签\n",
    "axs[-1].set_xlabel('小时', fontproperties=font_prop)\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "\n",
    "# 保存图为PDF文件\n",
    "plt.savefig('D:/研究生/毕业论文/草稿/图片/hour_level.png')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9c0414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795da873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008d678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "852da078",
   "metadata": {},
   "source": [
    "# 每小时直播数据的频数分布统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4960bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_multi_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/multi.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/multi.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/multi.xlsx\",\n",
    "              \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/multi.xlsx\"     ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931465c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取multi.xlsx文件\n",
    "multi_df = pd.concat([pd.read_excel(file_path) for file_path in file_multi_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b316e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据直播ID合并两个DataFrame\n",
    "merged_df = pd.merge(df_all, multi_df, on='room_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e72375",
   "metadata": {},
   "source": [
    "数据格式检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769f4be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表，用于存储格式有问题的 room_id\n",
    "invalid_room_ids = []\n",
    "\n",
    "# 遍历 merged_df 中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 获取当前行的 room_id 和 charts 列数据\n",
    "    room_id = row['room_id']\n",
    "    charts_data = row['charts']\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    charts_data = charts_data.replace(\"'\", \"\\\"\")\n",
    "    \n",
    "    try:\n",
    "        # 使用 json.loads() 将字符串解析为 JSON 对象\n",
    "        charts_list = json.loads(charts_data)\n",
    "    except json.JSONDecodeError:\n",
    "        # 如果解析失败，则记录该行的 room_id\n",
    "        invalid_room_ids.append(room_id)\n",
    "# 打印格式有问题的 room_id\n",
    "print(\"格式有问题的 room_id：\", len(invalid_room_ids))\n",
    "print(\"格式有问题的 room_id：\", invalid_room_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f198fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字典用于存储不同等级的 room_id\n",
    "room_ids_by_level = {}\n",
    "\n",
    "# 遍历 merged_df 中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 获取当前行的 room_id 和 level\n",
    "    room_id = row['room_id']\n",
    "    level = row['level']\n",
    "    if room_id in invalid_room_ids:\n",
    "        # 如果当前 level 不在字典中，则创建一个空列表存储该 level 的 room_id\n",
    "        if level not in room_ids_by_level:\n",
    "            room_ids_by_level[level] = []\n",
    "\n",
    "        # 将当前 room_id 添加到相应的 level 列表中\n",
    "        room_ids_by_level[level].append(room_id)\n",
    "\n",
    "# 指定保存路径\n",
    "save_path = \"D:/研究生/毕业论文/数据/有问题直播\"\n",
    "\n",
    "# 遍历 room_ids_by_level 字典，将每个 level 的 room_id 保存到对应的 txt 文件中\n",
    "for level, room_ids in room_ids_by_level.items():\n",
    "    # 拼接文件名\n",
    "    filename = os.path.join(save_path, f\"room_ids_level_{level}.txt\")\n",
    "    \n",
    "    # 将 room_ids 写入到 txt 文件中，每个 room_id 之间用逗号分隔\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(','.join(map(str, room_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9fd89",
   "metadata": {},
   "source": [
    "应该是平台的直播数据本身的原因，爬了两次都是同样直播间的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57e686a",
   "metadata": {},
   "source": [
    "删除错误格式数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13fde60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除格式有问题的 room_id 对应的行\n",
    "merged_df = merged_df[~merged_df['room_id'].isin(invalid_room_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee18c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表，用于存储展开后的数据\n",
    "expanded_data_list = []\n",
    "\n",
    "# 遍历 merged_df 中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 获取当前行的 room_id 和 charts 列数据\n",
    "    room_id = row['room_id']\n",
    "    level = row['level']\n",
    "    charts_data = row['charts']\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    charts_data = charts_data.replace(\"'\", \"\\\"\")\n",
    "    \n",
    "    # 使用 json.loads() 将字符串解析为 JSON 对象\n",
    "    charts_list = json.loads(charts_data)\n",
    "    \n",
    "    # 遍历每个直播间的 charts 数据\n",
    "    for chart in charts_list:\n",
    "        # 将每个字典添加到列表中，并添加 room_id\n",
    "        chart['room_id'] = room_id\n",
    "        chart['level'] = level\n",
    "        expanded_data_list.append(chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "194aeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将列表转换为 DataFrame\n",
    "expanded_data = pd.DataFrame(expanded_data_list)\n",
    "\n",
    "# 将 time_node 列转换为日期时间类型\n",
    "expanded_data['time_node'] = pd.to_datetime(expanded_data['time_node'], unit='s')\n",
    "\n",
    "expanded_data['time_node'] = expanded_data['time_node'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 根据 time_node 列提取日期\n",
    "expanded_data['date'] = expanded_data['time_node'].dt.date\n",
    "\n",
    "# 提取小时\n",
    "expanded_data['hour'] = expanded_data['time_node'].dt.hour\n",
    "\n",
    "# 提取分钟\n",
    "expanded_data['minute'] = expanded_data['time_node'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4282d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出需要增加的列名\n",
    "columns_to_increment = ['real_time_user', 'leave_user', 'user_count']\n",
    "\n",
    "# 将这些列的数据全部加 1\n",
    "expanded_data[columns_to_increment] = expanded_data[columns_to_increment] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6f92b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 过滤掉日期为2024年3月15日的数据\n",
    "# expanded_data_filtered = expanded_data[expanded_data['date'] != pd.to_datetime('2024-03-15').date()]\n",
    "\n",
    "# # 按日期和小时分组并计算每小时的在线主播人数和在线观众人数\n",
    "# hourly_stats = expanded_data_filtered.groupby(['date', 'hour']).agg({'room_id': 'nunique', 'real_time_user': 'sum'})\n",
    "\n",
    "# # 重命名列\n",
    "# hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# # 打印统计结果\n",
    "# print(hourly_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c9317",
   "metadata": {},
   "source": [
    "## 不同时间粒度的数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce9b9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据筛选，只需要晚上时间段的直播\n",
    "filtered_data = expanded_data[expanded_data['hour'].isin([18, 19, 20, 21, 22, 23])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db5b17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes(filtered_data, time_interval='5T', save_path='feature_changes_by_level.png'):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "    \n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // (int(time_interval[:-1])) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id', 'level'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period', 'level'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period', 'level']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages['time_period_str'] = monthly_averages['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages['time_period'] = pd.to_datetime(monthly_averages['hour'].astype(str) + ':' + monthly_averages['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "    # 获取不同的等级\n",
    "    levels = monthly_averages['level'].unique()\n",
    "    num_levels = len(levels)\n",
    "\n",
    "    # 创建一个子图网格，根据等级数量决定行数\n",
    "    fig, axs = plt.subplots(num_levels, 1, figsize=(20, 4*num_levels), dpi=400, sharex=True)\n",
    "\n",
    "    # 确保 axs 是一个可迭代的对象\n",
    "    if num_levels == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    # 为每个等级绘制子图\n",
    "    for i, level in enumerate(levels):\n",
    "        level_data = monthly_averages[monthly_averages['level'] == level]\n",
    "        \n",
    "        # 绘制特征数据\n",
    "        axs[i].plot(level_data['time_period'], level_data['real_time_user'], marker='o', label='进场用户', color='blue')\n",
    "        axs[i].plot(level_data['time_period'], level_data['leave_user'], marker='x', label='离线用户', color='red')\n",
    "        axs[i].plot(level_data['time_period'], level_data['user_count'], marker='s', label='在线用户', color='green')\n",
    "        \n",
    "        # 设置标题和标签\n",
    "        axs[i].set_title(f'主播等级 {level} - 每{time_interval}特征变化', fontweight='bold', fontproperties=font_prop)\n",
    "        axs[i].set_ylabel('数量', fontweight='bold', fontproperties=font_prop)\n",
    "        axs[i].legend()\n",
    "\n",
    "    # 设置共享的 x 轴标签\n",
    "    axs[-1].set_xlabel('时间段', fontproperties=font_prop)\n",
    "\n",
    "    # 设置 x 轴刻度\n",
    "    axs[-1].xaxis.set_major_locator(mdates.MinuteLocator(interval=int(time_interval[:-1])))\n",
    "    axs[-1].xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    # 自动旋转 x 轴刻度标签\n",
    "    plt.setp(axs[-1].get_xticklabels(), rotation=45)\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "316172a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例调用\n",
    "plot_feature_changes(filtered_data, time_interval='1T', save_path='D:/研究生/毕业论文/草稿/图片/feature_changes_1min_by_level.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e163c0",
   "metadata": {},
   "source": [
    "## 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f06828bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = '10T'\n",
    "# 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "filtered_data_new = filtered_data.copy()\n",
    "filtered_data_new.loc[:, 'time_period'] = filtered_data_new['minute'] // (int(time_interval[:-1])) * int(time_interval[:-1])\n",
    "\n",
    "# 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "average_features = filtered_data_new.groupby(['date', 'hour', 'time_period', 'room_id', 'level'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "average_features['real_time_user'] = average_features['real_time_user'].round().astype(int)\n",
    "average_features['leave_user'] = average_features['leave_user'].round().astype(int)\n",
    "average_features['user_count'] = average_features['user_count'].round().astype(int)\n",
    "\n",
    "# 将同等级的直播间进行求和\n",
    "summed_features = average_features.groupby(['date', 'hour', 'time_period', 'level'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "# 获取所有唯一的等级\n",
    "levels = summed_features['level'].unique()\n",
    "\n",
    "# 对每个等级的数据进行提取\n",
    "for level in levels:\n",
    "    # 提取当前等级的数据\n",
    "    level_data = summed_features[summed_features['level'] == level]\n",
    "\n",
    "    # 删除不需要的列\n",
    "    level_data = level_data.drop(columns=['level'])\n",
    "    \n",
    "    # 保存到 CSV 文件\n",
    "    output_file = f'./处理数据/hourly_stats_level_{level}.csv'\n",
    "    level_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved data for level {level} to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb6d062",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './处理数据'\n",
    "\n",
    "# 处理每个级别的数据\n",
    "for level in [1, 2, 3]:  # 假设你有3个级别，调整为实际需要的级别\n",
    "    # 构建文件名\n",
    "    file_name = f'hourly_stats_level_{level}.csv'\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    \n",
    "    # 读取数据\n",
    "    hourly_stats = pd.read_csv(file_path)\n",
    "    \n",
    "    # 重命名列\n",
    "    hourly_stats.columns = ['date', 'hour', 'time_period', 'real_time_user', 'leave_user', 'user_count']\n",
    "    \n",
    "    # 确保数据按照日期、小时和时间段排序\n",
    "    hourly_stats = hourly_stats.sort_values(by=['date', 'hour', 'time_period'])\n",
    "    \n",
    "    # 创建匹配后的数据\n",
    "    merged_data = pd.DataFrame()\n",
    "\n",
    "    # 定义时间间隔的步长\n",
    "    time_intervals = list(range(0, 60, 10))  # 每隔10分钟\n",
    "    for i in range(len(time_intervals) - 1):\n",
    "        # 当前时间段和下一个时间段的分钟数\n",
    "        current_time_period = time_intervals[i]\n",
    "        next_time_period = time_intervals[i + 1]\n",
    "        \n",
    "        # 获取当前时间段和下一时间段的数据\n",
    "        current_time_data = hourly_stats[hourly_stats['time_period'] == current_time_period]\n",
    "        next_time_data = hourly_stats[hourly_stats['time_period'] == next_time_period]\n",
    "        \n",
    "        # 合并数据，确保同一天、同一小时的数据匹配\n",
    "        merged_time_data_1 = pd.merge(current_time_data, next_time_data, on=['date', 'hour'], suffixes=('', '_t'))\n",
    "\n",
    "        # 只保留匹配成功的行\n",
    "        if not merged_time_data_1.empty:\n",
    "            merged_data = pd.concat([merged_data, merged_time_data_1], axis=0)\n",
    "    \n",
    "    # 当前时间段和下一个时间段的分钟数\n",
    "    current_time_period = time_intervals[5]\n",
    "    next_time_period = time_intervals[0]\n",
    "\n",
    "    # 获取当前时间段和下一时间段的数据\n",
    "    current_time_data = hourly_stats[hourly_stats['time_period'] == current_time_period]\n",
    "    next_time_data = hourly_stats[hourly_stats['time_period'] == next_time_period].copy()\n",
    "\n",
    "    # 确保 next_time_data 的小时数比 current_time_data 的小时数多 1\n",
    "    next_time_data['hour'] -= 1\n",
    "    # 处理有点问题\n",
    "\n",
    "    # 合并数据，确保同一天且 next_time_data 的小时比 current_time_data 的小时多 1\n",
    "    merged_time_data_2 = pd.merge(\n",
    "        current_time_data,\n",
    "        next_time_data,\n",
    "        on=['date', 'hour'],  # 现在两个数据集的小时相同，但实际上 next_time_data 的小时比 current_time_data 多 1\n",
    "        suffixes=('', '_t')\n",
    "    )\n",
    "\n",
    "    # 只保留匹配成功的行\n",
    "    if not merged_time_data_2.empty:\n",
    "        merged_data = pd.concat([merged_data, merged_time_data_2], axis=0)\n",
    "    \n",
    "    # 丢弃不必要的列（如 'time_period_t' 列）\n",
    "    merged_data = merged_data.drop(columns=['time_period_t'])\n",
    "    merged_data = merged_data.drop(columns=['date'])\n",
    "\n",
    "    # 根据 hour 和 time_period 生成索引\n",
    "    index_mapping = {\n",
    "        (18, 0): 0, (18, 10): 1, (18, 20): 2, (18, 30): 3, (18, 40): 4, (18, 50): 5,\n",
    "        (19, 0): 6, (19, 10): 7, (19, 20): 8, (19, 30): 9, (19, 40): 10, (19, 50): 11,\n",
    "        (20, 0): 12, (20, 10): 13, (20, 20): 14, (20, 30): 15, (20, 40): 16, (20, 50): 17,\n",
    "        (21, 0): 18, (21, 10): 19, (21, 20): 20, (21, 30): 21, (21, 40): 22, (21, 50): 23,\n",
    "        (22, 0): 24, (22, 10): 25, (22, 20): 26, (22, 30): 27, (22, 40): 28, (22, 50): 29,\n",
    "        (23, 0): 30, (23, 10): 31, (23, 20): 32, (23, 30): 33, (23, 40): 34, (23, 50): 35,\n",
    "    }\n",
    "\n",
    "    # 应用索引映射\n",
    "    merged_data['index'] = merged_data.apply(lambda row: index_mapping.get((row['hour'], row['time_period']), -1), axis=1)\n",
    "\n",
    "    # 将索引列移动到第一列\n",
    "    merged_data = merged_data[['index'] + [col for col in merged_data.columns if col != 'index']]\n",
    "\n",
    "\n",
    "    # 丢弃不必要的列（如 'time_period_t' 列）\n",
    "    merged_data = merged_data.drop(columns=['hour'])\n",
    "    merged_data = merged_data.drop(columns=['time_period'])\n",
    "\n",
    "\n",
    "    # 保存处理后的数据\n",
    "    output_file_path = os.path.join(data_folder, f'processed_hourly_stats_level_{level}.csv')\n",
    "    merged_data.to_csv(output_file_path, index=False)\n",
    "    print(f'Processed data saved for level {level} to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36db09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "360b13ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据文件夹路径\n",
    "data_folder = './处理数据'\n",
    "\n",
    "# 假设你有 3 个等级\n",
    "levels = [1, 2, 3]  \n",
    "level_change_rate_data = {}\n",
    "\n",
    "for level in levels:\n",
    "    # 构建文件路径\n",
    "    file_path = os.path.join(data_folder, f'hourly_stats_level_{level}.csv')\n",
    "    \n",
    "    # 读取当前等级的数据\n",
    "    level_data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 确保数据按照日期、小时和时间段排序\n",
    "    level_data = level_data.sort_values(by=['date', 'hour', 'time_period'])\n",
    "    \n",
    "    # 按照 'hour', 'time_period' 分组，计算 'real_time_user' 特征的平均值\n",
    "    avg_data = level_data.groupby(['hour', 'time_period'])[['real_time_user']].mean().reset_index()\n",
    "    \n",
    "    # 计算变化率\n",
    "    avg_data['next_real_time_user'] = avg_data['real_time_user'].shift(-1)\n",
    "    avg_data['change_rate'] = (avg_data['next_real_time_user'] - avg_data['real_time_user']) / avg_data['real_time_user']\n",
    "    \n",
    "    # 处理时间跨小时的情况：当前的50分钟与下一小时的0分钟\n",
    "    for idx, row in avg_data.iterrows():\n",
    "        if row['time_period'] == 50:  # 如果是50分钟\n",
    "            # 找到下一行的时间是下一小时的0分钟的数据\n",
    "            next_index = idx + 1\n",
    "            if next_index < len(avg_data):\n",
    "                next_row = avg_data.iloc[next_index]\n",
    "                if next_row['hour'] == (row['hour'] + 1) % 24 and next_row['time_period'] == 0:\n",
    "                    avg_data.at[idx, 'change_rate'] = (\n",
    "                        next_row['real_time_user'] - row['real_time_user']\n",
    "                    ) / row['real_time_user']\n",
    "            else:\n",
    "                # 如果没有合适的下一行，则设置为NaN\n",
    "                avg_data.at[idx, 'change_rate'] = float('nan')\n",
    "    \n",
    "    # 删除不需要的列\n",
    "    avg_data = avg_data.drop(columns=['next_real_time_user'])\n",
    "\n",
    "    avg_data = avg_data.drop(columns=['hour'])\n",
    "    avg_data = avg_data.drop(columns=['time_period'])\n",
    "    avg_data = avg_data.drop(columns=['real_time_user'])\n",
    "\n",
    "    # 创建索引列\n",
    "    avg_data['index'] = avg_data.reset_index().index+1\n",
    "    \n",
    "    # 将索引列移动到第一列\n",
    "    avg_data = avg_data[['index'] + [col for col in avg_data.columns if col != 'index']]\n",
    "\n",
    "    \n",
    "    # 保存每个等级的变化率数据\n",
    "    output_file = os.path.join(data_folder, f'change_rate_real_time_user_level_{level}.csv')\n",
    "    avg_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved change rate data for level {level} to {output_file}')\n",
    "\n",
    "    # 将结果存储到字典中，以便后续使用\n",
    "    level_change_rate_data[level] = avg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beea017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c55db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1293a21",
   "metadata": {},
   "source": [
    "## average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc61bdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将时间戳转换为日期和小时\n",
    "# expanded_data['hour'] = pd.to_datetime(expanded_data['time_node'], unit='s').dt.hour\n",
    "\n",
    "# # 过滤掉日期为2024年3月15日的数据\n",
    "# expanded_data_filtered = expanded_data[expanded_data['date'] != pd.to_datetime('2024-03-15').date()]\n",
    "\n",
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data.groupby(['date', 'hour', 'room_id']).agg({'real_time_user': 'mean'}).reset_index()\n",
    "print(hourly_stats)\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats = hourly_stats.groupby(['date', 'hour']).agg({'room_id': 'count', 'real_time_user': 'sum'})\n",
    "print(hourly_stats)\n",
    "# 重命名列\n",
    "hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "\n",
    "print(hourly_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "081a4878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 10), dpi=200, sharex=True)\n",
    "\n",
    "# 绘制每天每小时的在线主播人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['online_streamers'].plot(ax=axs[0], marker='o', label=f'Day {day}')\n",
    "\n",
    "# 设置第一个子图的图例、标题和轴标签\n",
    "# axs[0].legend()\n",
    "axs[0].set_title('Hourly Online Streamers')\n",
    "axs[0].set_ylabel('Count')\n",
    "# axs[0].grid(True)\n",
    "axs[0].set_xticks(range(24))\n",
    "\n",
    "# 绘制每天每小时的在线观众人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['online_viewers'].plot(ax=axs[1], marker='x', label=f'Day {day}')\n",
    "\n",
    "# 设置第二个子图的图例、标题和轴标签\n",
    "# axs[1].legend()\n",
    "axs[1].set_title('Hourly Online Viewers')\n",
    "axs[1].set_xlabel('Hour')\n",
    "axs[1].set_ylabel('Count')\n",
    "# axs[1].grid(True)\n",
    "axs[1].set_xticks(range(0, 25, 5))\n",
    "axs[1].set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50758fb6",
   "metadata": {},
   "source": [
    "可以看出，主播和观众的峰值位置保持一致，发展趋势也保持一致。同时值得一提的是，随着数据量的增多，可以发现每天的主播、观众都在一条曲线上稳定地上下波动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330bd00a",
   "metadata": {},
   "source": [
    "排除每个小时直播场次的差异，每个小时下每场直播间的在线观众也是有所差异的。不应该取平均值，这里再取平均值的含义，每个点都变为某一天的某个小时下，每场直播的平均观众。而我需要的是每个小时有多少场直播，平台总的在线观众。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8bebab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg = hourly_stats.groupby('hour').mean().reset_index()\n",
    "\n",
    "# 对平均值取整\n",
    "hourly_avg['online_streamers'] = hourly_avg['online_streamers'].round().astype(int)\n",
    "hourly_avg['online_viewers'] = hourly_avg['online_viewers'].round().astype(int)\n",
    "\n",
    "# 将结果保存到 CSV 文件中\n",
    "hourly_avg.to_csv('D:/研究生/毕业论文/数据/处理后数据/hourly_avg_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd819be8",
   "metadata": {},
   "source": [
    "## max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dff98f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data_filtered.groupby(['date', 'hour', 'room_id']).agg({'real_time_user': 'max'}).reset_index()\n",
    "\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats = hourly_stats.groupby(['date', 'hour']).agg({'room_id': 'nunique', 'real_time_user': 'sum'})\n",
    "\n",
    "# 重命名列\n",
    "hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "603ef789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 10), dpi=200, sharex=True)\n",
    "\n",
    "# 绘制每天每小时的在线主播人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['online_streamers'].plot(ax=axs[0], marker='o', label=f'Day {day}')\n",
    "\n",
    "# 设置第一个子图的图例、标题和轴标签\n",
    "# axs[0].legend()\n",
    "axs[0].set_title('Hourly Online Streamers')\n",
    "axs[0].set_ylabel('Count')\n",
    "# axs[0].grid(True)\n",
    "axs[0].set_xticks(range(24))\n",
    "\n",
    "# 绘制每天每小时的在线观众人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['online_viewers'].plot(ax=axs[1], marker='x', label=f'Day {day}')\n",
    "\n",
    "# 设置第二个子图的图例、标题和轴标签\n",
    "# axs[1].legend()\n",
    "axs[1].set_title('Hourly Online Viewers')\n",
    "axs[1].set_xlabel('Hour')\n",
    "axs[1].set_ylabel('Count')\n",
    "# axs[1].grid(True)\n",
    "axs[1].set_xticks(range(0, 25, 5))\n",
    "axs[1].set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059c3fee",
   "metadata": {},
   "source": [
    "再取平均值看直播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e657a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_max = hourly_stats.groupby('hour').mean().reset_index()\n",
    "\n",
    "# 对平均值取整\n",
    "hourly_max['online_streamers'] = hourly_max['online_streamers'].round().astype(int)\n",
    "hourly_max['online_viewers'] = hourly_max['online_viewers'].round().astype(int)\n",
    "\n",
    "# 将结果保存到 CSV 文件中\n",
    "hourly_max.to_csv('D:/研究生/毕业论文/数据/处理后数据/hourly_max_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7ba74",
   "metadata": {},
   "source": [
    "# 处理后数据（不合格）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1707d6be",
   "metadata": {},
   "source": [
    "## 主播和总观众人数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed55ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 10), dpi=200, sharex=True)\n",
    "\n",
    "# 绘制主播数的对比图\n",
    "axs[0].plot(hourly_avg['hour'], hourly_avg['online_streamers'], label='Average Streamers', marker='o')\n",
    "axs[0].plot(hourly_max['hour'], hourly_max['online_streamers'], label='Max Streamers', marker='x')\n",
    "axs[0].set_title('Comparison of Streamers')\n",
    "axs[0].set_ylabel('Count')\n",
    "axs[0].legend()\n",
    "\n",
    "# 绘制观众数的对比图\n",
    "axs[1].plot(hourly_avg['hour'], hourly_avg['online_viewers'], label='Average Viewers', marker='o')\n",
    "axs[1].plot(hourly_max['hour'], hourly_max['online_viewers'], label='Max Viewers', marker='x')\n",
    "axs[1].set_title('Comparison of Viewers')\n",
    "axs[1].set_xlabel('Hour')\n",
    "axs[1].set_ylabel('Count')\n",
    "axs[1].legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9559ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35e76cd0",
   "metadata": {},
   "source": [
    "## 提取各类观众分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "415c9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data_filtered.groupby(['date', 'hour', 'room_id']).agg({'real_time_user': 'mean','leave_user': 'mean','user_count': 'mean'}).reset_index()\n",
    "\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats['leave_user'] = hourly_stats['leave_user'].round().astype(int)\n",
    "hourly_stats['user_count'] = hourly_stats['user_count'].round().astype(int)\n",
    "# hourly_stats = hourly_stats.groupby(['hour']).agg({'room_id': 'nunique', 'real_time_user': 'sum'})\n",
    "\n",
    "# 重命名列\n",
    "# hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5af48c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据框保存为 CSV 文件\n",
    "hourly_stats.to_csv('D:/研究生/毕业论文/数据/处理后数据/avg_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85782190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data_filtered.groupby(['date', 'hour', 'room_id']).agg({'real_time_user': 'max','leave_user': 'max','user_count': 'max'}).reset_index()\n",
    "\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats['leave_user'] = hourly_stats['leave_user'].round().astype(int)\n",
    "hourly_stats['user_count'] = hourly_stats['user_count'].round().astype(int)\n",
    "# hourly_stats = hourly_stats.groupby(['hour']).agg({'room_id': 'nunique', 'real_time_user': 'sum'})\n",
    "\n",
    "# 重命名列\n",
    "# hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "98e1c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据框保存为 CSV 文件\n",
    "hourly_stats.to_csv('D:/研究生/毕业论文/数据/处理后数据/max_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3de4c0a",
   "metadata": {},
   "source": [
    "网络的研究有可能没有y，可能看网络结构的变化模式。双层网络这种网络结构或子网络结构的变化是否会对最终的观点的偏好影响。节点和边的特征改变，导致子网络特征的改变。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3bb589",
   "metadata": {},
   "source": [
    "# 正确处理后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b997b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/info.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/info.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/info.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/info.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd973cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_multi_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/multi.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/multi.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/multi.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/multi.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abf247d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_detail_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/detail.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/detail.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/detail.xlsx\",\n",
    "              \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/detail.xlsx\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c9273c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_charts_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/charts.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/charts.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/charts.xlsx\",\n",
    "              \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/charts.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2ea4ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_analysis_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/analysis.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/analysis.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/analysis.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/analysis.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8271e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空DataFrame用于存储所有数据\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "# 循环读取每个文件并合并数据\n",
    "# 假设文件名中包含等级信息，从文件路径中提取等级\n",
    "for file_path in file_paths:\n",
    "    if '10-100' in file_path:\n",
    "        level = '3'\n",
    "    elif '100-500' in file_path:\n",
    "        level = '2'\n",
    "    elif '500-1000' in file_path:\n",
    "        level = '1'\n",
    "    elif '1000' in file_path:\n",
    "        level = '1'\n",
    "    else:\n",
    "        level = 'Unknown'  # 处理未知等级的文件\n",
    "    # 读取xlsx文件\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # 添加等级列\n",
    "    df['level'] = level\n",
    "    \n",
    "    # 合并数据\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "# 将 begin_time 和 room_finish_time 列的时间戳转换为 pandas 的日期时间格式\n",
    "df_all['begin_time'] = pd.to_datetime(df_all['begin_time'], unit='s')\n",
    "df_all['room_finish_time'] = pd.to_datetime(df_all['room_finish_time'], unit='s')\n",
    "\n",
    "# 将日期时间列的时区从 UTC 转换为北京时间\n",
    "df_all['begin_time'] = df_all['begin_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "df_all['room_finish_time'] = df_all['room_finish_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 提取日期作为新的列\n",
    "df_all['begin_date'] = df_all['begin_time'].dt.date\n",
    "df_all['end_date'] = df_all['room_finish_time'].dt.date\n",
    "\n",
    "# 将时间戳转换为日期和小时\n",
    "df_all['begin_hour'] = pd.to_datetime(df_all['begin_time'], unit='s').dt.hour\n",
    "df_all['end_hour'] = pd.to_datetime(df_all['room_finish_time'], unit='s').dt.hour\n",
    "\n",
    "# 计算直播时长\n",
    "df_all['duration'] = df_all['room_finish_time'] - df_all['begin_time']\n",
    "\n",
    "# 如果你想要的是以小时为单位的直播时长，可以将时间差转换为小时\n",
    "df_all['duration_hours'] = df_all['duration'] / pd.Timedelta(hours=1)\n",
    "\n",
    "# 选择感兴趣的列\n",
    "columns_of_interest = ['room_id', 'talent_id', 'follower_count', 'following_count',\n",
    "                       'average_residence_time', 'total_user', 'begin_time', 'room_finish_time', 'average_user_count',\n",
    "                       'like_count', 'duration_hours', 'level', 'is_take_product', 'begin_date', 'end_date','increment_follower_count',\n",
    "                       'begin_hour', 'end_hour'\n",
    "                      ]\n",
    "\n",
    "# 将指定列保存\n",
    "df_info = df_all[columns_of_interest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42c59822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取multi.xlsx文件\n",
    "df_multi = pd.concat([pd.read_excel(file_path) for file_path in file_multi_paths])\n",
    "df_multi = df_multi[['room_id','charts']]\n",
    "df_detail = pd.concat([pd.read_excel(file_path) for file_path in file_detail_paths])\n",
    "df_detail = df_detail[['room_id', 'barrage_count', 'interaction_percent']]\n",
    "df_charts = pd.concat([pd.read_excel(file_path) for file_path in file_charts_paths])\n",
    "df_charts = df_charts[['room_id', 'total_count']]\n",
    "df_analysis = pd.concat([pd.read_excel(file_path) for file_path in file_analysis_paths])\n",
    "df_analysis = df_analysis[['room_id', 'age', 'female', 'male', 'province']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f124141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据 room_id 合并 DataFrame\n",
    "merged_df = pd.merge(df_info, df_multi, on='room_id', how='inner')\n",
    "merged_df = pd.merge(merged_df, df_detail, on='room_id', how='inner')\n",
    "merged_df = pd.merge(merged_df, df_charts, on='room_id', how='inner')\n",
    "merged_df = pd.merge(merged_df, df_analysis, on='room_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbb84e",
   "metadata": {},
   "source": [
    "## 直播持续时间的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0edc3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 使用Seaborn绘制直方图\n",
    "sns.histplot(merged_df['duration_hours'], bins=30, color='skyblue', edgecolor='black')\n",
    "\n",
    "# 添加标题和轴标签\n",
    "plt.title('Distribution of Duration')\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9449d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['duration_hours'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980778c2",
   "metadata": {},
   "source": [
    "一个主播的上线和下线应该根据直播的开始时间和结束时间来确定，duration_hours只能说明一个在线时长问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a0a73",
   "metadata": {},
   "source": [
    "## 主播的上线和离线分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55481da",
   "metadata": {},
   "source": [
    "删除有问题的直播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab5abfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_problem_paths = [\"D:/研究生/毕业论文/数据/有问题直播/room_ids_level_Level 1.txt\",\n",
    "                      \"D:/研究生/毕业论文/数据/有问题直播/room_ids_level_Level 2.txt\",\n",
    "                      \"D:/研究生/毕业论文/数据/有问题直播/room_ids_level_Level 3.txt\",\n",
    "                      \"D:/研究生/毕业论文/数据/有问题直播/room_ids_level_Level 4.txt\"\n",
    "                     ]\n",
    "# 读取所有问题文件中的 room_id\n",
    "problem_room_ids = []\n",
    "for file_problem_path in file_problem_paths:\n",
    "    with open(file_problem_path, 'r') as file:\n",
    "        # 逐行读取文件中的 room_id，并添加到列表中\n",
    "        for line in file:\n",
    "            room_ids = line.strip().split(',')\n",
    "            problem_room_ids.extend(room_ids)\n",
    "\n",
    "# 将 room_id 转换为字符串类型\n",
    "problem_room_ids = list(map(str, problem_room_ids))\n",
    "\n",
    "# 从 merged_df 中过滤掉包含问题 room_id 的行\n",
    "merged_df = merged_df[~merged_df['room_id'].isin(problem_room_ids)]\n",
    "\n",
    "# # 打印过滤后的 DataFrame\n",
    "# print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9df6fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 过滤掉日期为2024年3月15日的数据\n",
    "# merged_df = merged_df[merged_df['begin_date'] != pd.to_datetime('2024-03-15').date()]\n",
    "\n",
    "# 按日期和小时分组并计算每小时的在线主播人数和在线观众人数\n",
    "hourly_stats = merged_df.groupby(['begin_date', 'begin_hour']).agg({'room_id': 'nunique'})\n",
    "\n",
    "# 重命名列\n",
    "hourly_stats.rename(columns={'room_id': 'online_streamers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "80c77fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "# 遍历每一天的数据\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    # 绘制每天每小时的在线主播人数和在线观众人数的折线图\n",
    "    data['online_streamers'].plot(ax=ax, marker='o', label=f'Day {day} - Online Streamers')\n",
    "\n",
    "# 设置图例、标题和轴标签\n",
    "# ax.legend()\n",
    "ax.set_title('Hourly New Online Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('New Online Streamers')\n",
    "# ax.grid(True)\n",
    "\n",
    "# 设置横坐标轴刻度和标签\n",
    "ax.set_xticks(range(0, 25, 5))\n",
    "ax.set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf76eb4",
   "metadata": {},
   "source": [
    "这个和后面的图有问题，因为每一天的某个小时小有缺失的值，它没有画出缺失的值。平均图是对的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c91c075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg = hourly_stats.groupby('begin_hour').mean().reset_index()\n",
    "hourly_avg['online_streamers'] = hourly_avg['online_streamers'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4013193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "ax.plot(hourly_avg['begin_hour'], hourly_avg['online_streamers'], label='Average Streamers', marker='o')\n",
    "\n",
    "# 设置图例、标题和轴标签\n",
    "# ax.legend()\n",
    "ax.set_title('Hourly Average New Online Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('New Average Online Streamers')\n",
    "# ax.grid(True)\n",
    "\n",
    "# 设置横坐标轴刻度和标签\n",
    "ax.set_xticks(range(0, 25, 5))\n",
    "ax.set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27c972da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期和小时分组并计算每小时的在线主播人数和在线观众人数\n",
    "hourly_stats_off = merged_df.groupby(['end_date', 'end_hour']).agg({'room_id': 'nunique'})\n",
    "\n",
    "# 重命名列\n",
    "hourly_stats_off.rename(columns={'room_id': 'offline_streamers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats_off)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79b55c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg_off = hourly_stats_off.groupby('end_hour').mean().reset_index()\n",
    "hourly_avg_off['offline_streamers'] = hourly_avg_off['offline_streamers'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ddaf42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "ax.plot(hourly_avg_off['end_hour'], hourly_avg_off['offline_streamers'], label='Average Streamers', marker='o')\n",
    "\n",
    "# 设置图例、标题和轴标签\n",
    "# ax.legend()\n",
    "ax.set_title('Hourly Average New Offline Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('New Average Offline Streamers')\n",
    "# ax.grid(True)\n",
    "\n",
    "# 设置横坐标轴刻度和标签\n",
    "ax.set_xticks(range(0, 25, 5))\n",
    "ax.set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c704d7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计一个小时内一直直播的直播数\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 创建一个空的字典来存储每个小时范围内直播数\n",
    "hourly_live_count = {}\n",
    "\n",
    "# 遍历数据框中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 计算直播时长（以小时为单位）\n",
    "    duration_hours = row['room_finish_time'] - row['begin_time']\n",
    "    \n",
    "    # 如果直播时长大于1小时，则统计每个小时内一直在直播的直播数\n",
    "    if duration_hours > pd.Timedelta(hours=1):\n",
    "        # 生成直播开始时间和结束时间之间的小时范围\n",
    "        hour_range = pd.date_range(start=row['begin_time'], end=row['room_finish_time'], freq='H')\n",
    "        \n",
    "        # 统计每个小时范围内的直播数\n",
    "        for hour in hour_range[1:]:\n",
    "            # 提取日期和小时部分作为键\n",
    "            hour_key = (hour.date(), hour.hour)\n",
    "            \n",
    "            # 更新直播数\n",
    "            if hour_key not in hourly_live_count:\n",
    "                hourly_live_count[hour_key] = 1\n",
    "            else:\n",
    "                hourly_live_count[hour_key] += 1\n",
    "\n",
    "# 将字典转换为数据框\n",
    "hourly_live_count_df = pd.DataFrame(list(hourly_live_count.items()), columns=['begin_time', 'same_streamers'])\n",
    "\n",
    "# 将起始时间和结束时间拆分为两列，并设置为索引\n",
    "hourly_live_count_df[['begin_date', 'begin_hour']] = pd.DataFrame(hourly_live_count_df['begin_time'].tolist(), index=hourly_live_count_df.index)\n",
    "hourly_live_count_df = hourly_live_count_df.set_index(['begin_date', 'begin_hour'])\n",
    "\n",
    "# 打印结果\n",
    "print(hourly_live_count_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "524e54ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除某列\n",
    "hourly_live_count_df.drop(columns=['begin_time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55a19e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_live_count_avg = hourly_live_count_df.groupby('begin_hour').mean().reset_index()\n",
    "hourly_live_count_avg['same_streamers'] = hourly_live_count_avg['same_streamers'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0808a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "ax.plot(hourly_live_count_avg['begin_hour'], hourly_live_count_avg['same_streamers'], label='Average Streamers', marker='o')\n",
    "\n",
    "# 设置图例、标题和轴标签\n",
    "# ax.legend()\n",
    "ax.set_title('Hourly Average New Same Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('New Average Same Streamers')\n",
    "# ax.grid(True)\n",
    "\n",
    "# # 设置横坐标轴刻度和标签\n",
    "# ax.set_xticks(range(0, 25, 5))\n",
    "# ax.set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e492f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a17404f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出开始时间和结束时间在同一天，并且在同一小时的直播\n",
    "same_day_same_hour = merged_df[(merged_df['begin_time'].dt.date == merged_df['room_finish_time'].dt.date) & \n",
    "                               (merged_df['begin_time'].dt.hour == merged_df['room_finish_time'].dt.hour)]\n",
    "\n",
    "# 按日期和小时分组并计算每小时的直播数量\n",
    "hourly_stats_same_hour = same_day_same_hour.groupby([same_day_same_hour['begin_time'].dt.date, \n",
    "                                                     same_day_same_hour['room_finish_time'].dt.hour]).agg({'room_id': 'nunique'})\n",
    "\n",
    "hourly_stats_same_hour.rename(columns={'room_id': 'same_streamers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "print(hourly_stats_same_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59a6b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg_same = hourly_stats_same_hour.groupby('room_finish_time').mean().reset_index()\n",
    "hourly_avg_same['same_streamers'] = hourly_avg_same['same_streamers'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03a7df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "ax.plot(hourly_avg_same['room_finish_time'], hourly_avg_same['same_streamers'], label='Average Streamers', marker='o')\n",
    "\n",
    "# 设置图例、标题和轴标签\n",
    "# ax.legend()\n",
    "ax.set_title('Hourly Average New Same Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('New Average Same Streamers')\n",
    "# ax.grid(True)\n",
    "\n",
    "# # 设置横坐标轴刻度和标签\n",
    "# ax.set_xticks(range(0, 25, 5))\n",
    "# ax.set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374509d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9e69b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算总在线直播并取整,包括begin_hour在这个小时，end_hour在这个小时，以及两者同时在这个小时，和一直在这个小时\n",
    "hourly_avg_stats_df = (hourly_avg['online_streamers'] + hourly_avg_off['offline_streamers'] - hourly_avg_same['same_streamers']\n",
    "                      +hourly_live_count_avg['same_streamers']).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7ae67ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"D:/研究生/毕业论文/数据/处理后数据/hourly_avg_stats.csv\"\n",
    "hourly_avg_stats_df_1 = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "633965e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "# 绘制观众数的对比图\n",
    "ax.plot(hourly_avg['begin_hour'], hourly_avg['online_streamers'], label='Average Online Streamers', marker='o')\n",
    "ax.plot(hourly_avg_off['end_hour'], hourly_avg_off['offline_streamers'], label='Average Offline Streamers', marker='x')\n",
    "ax.plot(hourly_avg_same['room_finish_time'], hourly_avg_same['same_streamers'], label='Average Short Streamers', marker='s')\n",
    "ax.plot(hourly_live_count_avg['begin_hour'], hourly_live_count_avg['same_streamers'], label='Average Long Streamers', marker='p')\n",
    "ax.plot(hourly_avg_same['room_finish_time'], hourly_avg_stats_df, label='Average Streamers', marker='+')\n",
    "ax.plot(hourly_avg_same['room_finish_time'], hourly_avg_stats_df_1['online_streamers'], label='Average Streamers 1', marker='*')\n",
    "ax.set_title('Comparison of Streamers')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229b57f",
   "metadata": {},
   "source": [
    "可以根据主播上线和离线的结果，计算每个小时新加入主播的个数，以及每个小时退出主播的概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6ac9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DataFrame 存储数据\n",
    "data = {\n",
    "    'begin_hour': hourly_avg['begin_hour'],\n",
    "    'online_streamers': hourly_avg['online_streamers'],\n",
    "    'offline_streamers': hourly_avg_off['offline_streamers'],\n",
    "    'short_streamers': hourly_avg_same['same_streamers'],\n",
    "    'long_streamers': hourly_live_count_avg['same_streamers'],\n",
    "    'average_streamers': hourly_avg_stats_df,\n",
    "    'average_streamers_1': hourly_avg_stats_df_1['online_streamers']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存 DataFrame 到 CSV 文件\n",
    "df.to_csv('D:/研究生/毕业论文/数据/处理后数据/streamers_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7a897",
   "metadata": {},
   "source": [
    "## 观众的在线、下线分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301056bc",
   "metadata": {},
   "source": [
    "连接到4.2节的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3a84f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data_filtered.groupby(['date', 'hour', 'room_id']).agg({'real_time_user': 'mean', 'leave_user': 'mean', 'user_count': 'mean'}).reset_index()\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats['leave_user'] = hourly_stats['leave_user'].round().astype(int)\n",
    "hourly_stats['user_count'] = hourly_stats['user_count'].round().astype(int)\n",
    "hourly_stats = hourly_stats.groupby(['date', 'hour']).agg({'real_time_user': 'sum', 'leave_user': 'sum', 'user_count': 'sum'})\n",
    "\n",
    "# # 重命名列\n",
    "# hourly_stats.rename(columns={'room_id': 'online_streamers', 'real_time_user': 'online_viewers'}, inplace=True)\n",
    "\n",
    "# 打印统计结果\n",
    "\n",
    "print(hourly_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f840dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 10), dpi=200, sharex=True)\n",
    "\n",
    "# 绘制每天每小时的在线主播人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['real_time_user'].plot(ax=axs[0], marker='o', label=f'Day {day}')\n",
    "\n",
    "# 设置第一个子图的图例、标题和轴标签\n",
    "# axs[0].legend()\n",
    "axs[0].set_title('Hourly Real Time User')\n",
    "axs[0].set_ylabel('Count')\n",
    "# axs[0].grid(True)\n",
    "axs[0].set_xticks(range(24))\n",
    "\n",
    "# 绘制每天每小时的在线观众人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['leave_user'].plot(ax=axs[1], marker='x', label=f'Day {day}')\n",
    "\n",
    "# 设置第二个子图的图例、标题和轴标签\n",
    "# axs[1].legend()\n",
    "axs[1].set_title('Hourly Leave User')\n",
    "axs[1].set_ylabel('Count')\n",
    "# axs[1].grid(True)\n",
    "axs[1].set_xticks(range(24))\n",
    "\n",
    "# 绘制每天每小时的在线观众人数的折线图\n",
    "for day, data in hourly_stats.groupby(level=0):\n",
    "    data['user_count'].plot(ax=axs[2], marker='*', label=f'Day {day}')\n",
    "\n",
    "# 设置第二个子图的图例、标题和轴标签\n",
    "# axs[1].legend()\n",
    "axs[2].set_title('Hourly User Count')\n",
    "axs[2].set_xlabel('Hour')\n",
    "axs[2].set_ylabel('Count')\n",
    "# axs[1].grid(True)\n",
    "axs[2].set_xticks(range(0, 25, 5))\n",
    "axs[2].set_xticklabels(range(0, 25, 5))\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f9212b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg = hourly_stats.groupby('hour').mean().reset_index()\n",
    "\n",
    "# 对平均值取整\n",
    "hourly_avg['real_time_user'] = hourly_avg['real_time_user'].round().astype(int)\n",
    "hourly_avg['leave_user'] = hourly_avg['leave_user'].round().astype(int)\n",
    "hourly_avg['user_count'] = hourly_avg['user_count'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85deac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "# 绘制观众数的对比图\n",
    "ax.plot(hourly_avg['hour'], hourly_avg['real_time_user'], label='Average Real Time User', marker='o')\n",
    "ax.plot(hourly_avg['hour'], hourly_avg['leave_user'], label='Average Leave User', marker='x')\n",
    "ax.plot(hourly_avg['hour'], hourly_avg['user_count'], label='Average User Count', marker='s')\n",
    "ax.set_title('Comparison of Users')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbea6156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 DataFrame 存储数据\n",
    "data = {\n",
    "    'begin_hour': hourly_avg['hour'],\n",
    "    'real_time_user': hourly_avg['real_time_user'],\n",
    "    'leave_user': hourly_avg['leave_user'],\n",
    "    'user_count': hourly_avg['user_count']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 保存 DataFrame 到 CSV 文件\n",
    "df.to_csv('D:/研究生/毕业论文/数据/处理后数据/user_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972297e",
   "metadata": {},
   "source": [
    "详细数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e4cfdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 按日期、小时和room_id分组并计算每小时每个房间的在线主播人数和在线观众人数\n",
    "hourly_stats = expanded_data_filtered.groupby(['date', 'hour', 'room_id', 'level']).agg({'real_time_user': 'mean', 'leave_user': 'mean',\n",
    "                                                                                'user_count': 'mean'}).reset_index()\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "hourly_stats['real_time_user'] = hourly_stats['real_time_user'].round().astype(int)\n",
    "hourly_stats['leave_user'] = hourly_stats['leave_user'].round().astype(int)\n",
    "hourly_stats['user_count'] = hourly_stats['user_count'].round().astype(int)\n",
    "hourly_stats = hourly_stats.groupby(['date', 'hour', 'level']).agg({'real_time_user': 'sum', 'leave_user': 'sum', 'user_count': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4967019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e389796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按小时分组计算平均值\n",
    "hourly_avg = hourly_stats.groupby(['hour', 'level']).mean().reset_index()\n",
    "\n",
    "# 对平均值取整\n",
    "hourly_avg['real_time_user'] = hourly_avg['real_time_user'].round().astype(int)\n",
    "hourly_avg['leave_user'] = hourly_avg['leave_user'].round().astype(int)\n",
    "hourly_avg['user_count'] = hourly_avg['user_count'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de8ee48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d709810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个小时所有等级的real_time_user总和\n",
    "hourly_totals = hourly_avg.groupby('hour')['real_time_user'].sum().reset_index()\n",
    "hourly_totals.rename(columns={'real_time_user': 'total_real_time_user'}, inplace=True)\n",
    "\n",
    "# 合并hourly_avg和hourly_totals以获取每小时的总real_time_user\n",
    "hourly_avg = pd.merge(hourly_avg, hourly_totals, on='hour')\n",
    "\n",
    "# 计算每个等级的real_time_user占该小时总和的比例\n",
    "hourly_avg['level_proportion'] = hourly_avg['real_time_user'] / hourly_avg['total_real_time_user']\n",
    "\n",
    "# 透视表，将每个小时的各等级比例转换为列\n",
    "hourly_proportions = hourly_avg.pivot_table(index='hour', columns='level', values='level_proportion', fill_value=0).reset_index()\n",
    "\n",
    "# 重命名列以便于理解\n",
    "hourly_proportions.columns.name = None  # 移除列名\n",
    "hourly_proportions.columns = ['hour', 'level1_proportion', 'level2_proportion', 'level3_proportion']\n",
    "\n",
    "# 显示结果\n",
    "print(hourly_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f60eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存 DataFrame 到 CSV 文件\n",
    "hourly_proportions.to_csv('D:/研究生/毕业论文/数据/处理后数据/user_data_xi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1756534",
   "metadata": {},
   "source": [
    "# 主播带货品牌之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b43775",
   "metadata": {},
   "source": [
    "## 不等等级之间的主播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b53c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空DataFrame用于存储所有数据\n",
    "df_all = pd.DataFrame()\n",
    "\n",
    "# 循环读取每个文件并合并数据\n",
    "# 假设文件名中包含等级信息，从文件路径中提取等级\n",
    "for file_path in file_paths:\n",
    "    if '10-100' in file_path:\n",
    "        level = '3'\n",
    "    elif '100-500' in file_path:\n",
    "        level = '2'\n",
    "    elif '500-1000' in file_path:\n",
    "        level = '1'\n",
    "    elif '1000' in file_path:\n",
    "        level = '1'\n",
    "    else:\n",
    "        level = 'Unknown'  # 处理未知等级的文件\n",
    "    # 读取xlsx文件\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # 添加等级列\n",
    "    df['level'] = level\n",
    "    \n",
    "    # 合并数据\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "# 将 begin_time 和 room_finish_time 列的时间戳转换为 pandas 的日期时间格式\n",
    "df_all['begin_time'] = pd.to_datetime(df_all['begin_time'], unit='s')\n",
    "# df_all['room_finish_time'] = pd.to_datetime(df_all['room_finish_time'], unit='s')\n",
    "\n",
    "# 将日期时间列的时区从 UTC 转换为北京时间\n",
    "df_all['begin_time'] = df_all['begin_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "# df_all['room_finish_time'] = df_all['room_finish_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 提取日期作为新的列\n",
    "df_all['begin_date'] = df_all['begin_time'].dt.date\n",
    "# df_all['end_date'] = df_all['room_finish_time'].dt.date\n",
    "\n",
    "# 将时间戳转换为日期和小时\n",
    "df_all['begin_hour'] = pd.to_datetime(df_all['begin_time'], unit='s').dt.hour\n",
    "# df_all['end_hour'] = pd.to_datetime(df_all['room_finish_time'], unit='s').dt.hour\n",
    "\n",
    "# # 计算直播时长\n",
    "# df_all['duration'] = df_all['room_finish_time'] - df_all['begin_time']\n",
    "\n",
    "# # 如果你想要的是以小时为单位的直播时长，可以将时间差转换为小时\n",
    "# df_all['duration_hours'] = df_all['duration'] / pd.Timedelta(hours=1)\n",
    "\n",
    "# 选择感兴趣的列\n",
    "columns_of_interest = ['room_id', 'talent_id', 'begin_time', 'level', 'is_take_product', 'begin_date', 'begin_hour']\n",
    "\n",
    "# 将指定列保存\n",
    "df_info = df_all[columns_of_interest]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f619724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计每个level下的直播间数量\n",
    "level_counts = df_info['level'].value_counts()\n",
    "\n",
    "# 计算总的直播间数量\n",
    "total_rooms = level_counts.sum()\n",
    "\n",
    "# 计算每个level的直播间数量占总直播间数量的比例\n",
    "level_percentages = level_counts / total_rooms\n",
    "\n",
    "# 打印结果\n",
    "print(level_percentages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1866fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "file_filters_paths = [\"D:/研究生/毕业论文/数据/主播数据/jieguo_1000(2024.03.16-2024.04.14)/filters.xlsx\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_500-1000(2024.03.16-2024.04.14)/filters.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_100-500(2024.03.16-2024.04.14)/filters.xlsx\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据/jieguo_10-100(2024.03.16-2024.04.14)/filters.xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cab7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filters = pd.concat([pd.read_excel(file_path) for file_path in file_filters_paths])\n",
    "df_filters = df_filters[['room_id','brand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba5161e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据直播ID合并两个DataFrame\n",
    "merged_df = pd.merge(df_info, df_filters, on='room_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82dbf758",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_room_ids = []\n",
    "\n",
    "# 遍历每个直播间的品牌信息\n",
    "for _, row in merged_df.iterrows():\n",
    "    brands = row['brand']\n",
    "    room_id = row['room_id']\n",
    "    # 将字符串中的 None 替换为 null\n",
    "    brands = brands.replace('None', 'null')\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    brands = brands.replace(\"\\'\", \"\\\"\")\n",
    "    \n",
    "    #name:“Dr.Ci:Labo/城野医生”针对字符串的冒号需要去除，json认为这是字典的一对键值\n",
    "    # 使用正则表达式去除 `\\` 之前，前一个双引号 `\"` 和斜杠之间的内容\n",
    "    brands = re.sub(r'\"[^\"]+/[^\"]+\"', 'null', brands)\n",
    "    \n",
    "    #针对name:\"L\"null，\n",
    "    # 使用正则表达式匹配符合条件的内容并进行替换\n",
    "    brands = re.sub(r':\\s*\"[^\"]*null', ':null', brands)\n",
    "    \n",
    "    #针对name:\"I\"MONE\"\n",
    "    brands = re.sub(r'\"[^\",:]*\"[^\",:]*\"', 'null', brands)\n",
    "    \n",
    "    #针对name:nullnull\n",
    "    brands = re.sub(r'nullnull', 'null', brands)\n",
    "\n",
    "    #针对}'\n",
    "    # 判断字符串的最后一位是否是]\n",
    "    if brands[-1] == '}' and brands[-1] != ']':\n",
    "        brands += ']'\n",
    "        \n",
    "    #针对z最后没有}]'  \n",
    "    if brands[-1] != '}' and brands[-1] != ']':\n",
    "        brands += '}]'\n",
    "        \n",
    "    #其余情况为数据爬取不全造成的原因，给予删除\n",
    "    \n",
    "    try:\n",
    "        # 使用 json.loads() 将字符串解析为 JSON 对象\n",
    "        brands = json.loads(brands)\n",
    "    except json.JSONDecodeError:\n",
    "        # 如果解析失败，则记录该行的 room_id\n",
    "        invalid_room_ids.append(room_id)\n",
    "# 打印格式有问题的 room_id\n",
    "print(\"格式有问题的 room_id：\", len(invalid_room_ids))\n",
    "# print(\"格式有问题的 room_id：\", invalid_room_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2324ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除格式有问题的 room_id 对应的行\n",
    "merged_df = merged_df[~merged_df['room_id'].isin(invalid_room_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69188e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 创建一个字典，用于存储统计结果\n",
    "statistics = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))\n",
    "\n",
    "# 遍历每个直播间的品牌信息\n",
    "for _, row in merged_df.iterrows():\n",
    "    begin_date = row['begin_date']\n",
    "    begin_hour = row['begin_hour']\n",
    "    level = row['level']\n",
    "    brands = row['brand']\n",
    "    \n",
    "    # 将字符串中的 None 替换为 null\n",
    "    brands = brands.replace('None', 'null')\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    brands = brands.replace(\"\\'\", \"\\\"\")\n",
    "    \n",
    "    #name:“Dr.Ci:Labo/城野医生”针对字符串的冒号需要去除，json认为这是字典的一对键值\n",
    "    # 使用正则表达式去除 `\\` 之前，前一个双引号 `\"` 和斜杠之间的内容\n",
    "    brands = re.sub(r'\"[^\"]+/[^\"]+\"', 'null', brands)\n",
    "    \n",
    "    #针对name:\"L\"null，\n",
    "    # 使用正则表达式匹配符合条件的内容并进行替换\n",
    "    brands = re.sub(r':\\s*\"[^\"]*null', ':null', brands)\n",
    "    \n",
    "    #针对name:\"I\"MONE\"\n",
    "    brands = re.sub(r'\"[^\",:]*\"[^\",:]*\"', 'null', brands)\n",
    "    \n",
    "    #针对name:nullnull\n",
    "    brands = re.sub(r'nullnull', 'null', brands)\n",
    "\n",
    "    #针对}'\n",
    "    # 判断字符串的最后一位是否是]\n",
    "    if brands[-1] == '}' and brands[-1] != ']':\n",
    "        brands += ']'\n",
    "        \n",
    "    #针对z最后没有}]'  \n",
    "    if brands[-1] != '}' and brands[-1] != ']':\n",
    "        brands += '}]'\n",
    "        \n",
    "    # 先转换为 JSON 格式\n",
    "    brands = json.loads(brands)\n",
    "    \n",
    "    # 提取每个品牌信息中的商品集合并进行统计\n",
    "    for brand_info in brands:\n",
    "        name = brand_info.get('id')\n",
    "        if name is not None:\n",
    "            statistics[begin_date][begin_hour][level].add(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e48d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ed4b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建字典来存储每个时间段内不同等级之间商品的交集和并集\n",
    "hourly_intersection = defaultdict(lambda: defaultdict(set))\n",
    "hourly_union = defaultdict(lambda: defaultdict(set))\n",
    "\n",
    "# 计算每个时间段内不同等级之间商品的交集和并集\n",
    "for date, hour_data in statistics.items():\n",
    "    for hour, level_data in hour_data.items():\n",
    "        # 将每个等级的商品集合转换为集合列表\n",
    "        level_sets = [set(products) for products in level_data.values()]\n",
    "        \n",
    "        # 计算不同等级之间商品的交集和并集\n",
    "        for i in range(len(level_sets)):\n",
    "            for j in range(i+1, len(level_sets)):\n",
    "                level1 = list(level_data.keys())[i]\n",
    "                level2 = list(level_data.keys())[j]\n",
    "                intersection = level_sets[i].intersection(level_sets[j])\n",
    "                union = level_sets[i].union(level_sets[j])\n",
    "                \n",
    "                # 存储交集和并集\n",
    "                hourly_intersection[date][(hour, level1, level2)] = intersection\n",
    "                hourly_union[date][(hour, level1, level2)] = union\n",
    "\n",
    "# 创建字典来存储每个时间段内不同等级之间商品交集和并集的数量\n",
    "hourly_intersection_count = defaultdict(lambda: defaultdict(int))\n",
    "hourly_union_count = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# 计算每个时间段内不同等级之间商品交集和并集的数量\n",
    "for date, hour_data in hourly_intersection.items():\n",
    "    for hour_level, intersection in hour_data.items():\n",
    "        union = hourly_union[date][hour_level]\n",
    "        intersection_count = len(intersection)\n",
    "        union_count = len(union)\n",
    "        \n",
    "        # 存储交集和并集的数量\n",
    "        hourly_intersection_count[date][hour_level] = intersection_count\n",
    "        hourly_union_count[date][hour_level] = union_count\n",
    "\n",
    "# 计算每一天每小时下商品交集除以并集的概率\n",
    "hourly_probability = defaultdict(lambda: defaultdict(float))\n",
    "for date, hour_data in hourly_intersection_count.items():\n",
    "    for hour_level, intersection_count in hour_data.items():\n",
    "        union_count = hourly_union_count[date][hour_level]\n",
    "        \n",
    "        # 计算概率，避免除数为0的情况\n",
    "        if union_count != 0:\n",
    "            probability = intersection_count / union_count\n",
    "        else:\n",
    "            probability = 0\n",
    "        \n",
    "        # 存储概率\n",
    "        hourly_probability[date][hour_level] = probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ba3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b332b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将嵌套字典展开\n",
    "flat_hourly_probability = []\n",
    "for date, hour_data in hourly_probability.items():\n",
    "    for hour_level, probability in hour_data.items():\n",
    "        hour, level1, level2 = hour_level\n",
    "        flat_hourly_probability.append({'begin_date': date, 'begin_hour': hour, 'level1': level1, 'level2': level2, 'probability': probability})\n",
    "\n",
    "# 创建 DataFrame\n",
    "hourly_probability_df = pd.DataFrame(flat_hourly_probability)\n",
    "\n",
    "# 打印结果\n",
    "print(hourly_probability_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cd7a263",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de789c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按日期和小时分组并计算每小时的在线主播人数和在线观众人数\n",
    "# hourly_probability_df = hourly_probability_df.groupby(['begin_hour', 'level1', 'level2']).mean().reset_index()\n",
    "hourly_probability_df = hourly_probability_df.groupby(['begin_hour', 'level1', 'level2']).agg({'probability': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ce0eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成所有可能的组合\n",
    "possible_combinations = pd.DataFrame(list(itertools.product(range(24), ['1', '2'], [ '2', '3'])))\n",
    "\n",
    "# 去除level1=level2的组合\n",
    "possible_combinations = possible_combinations[possible_combinations[1] != possible_combinations[2]]\n",
    "\n",
    "# 将其与当前 DataFrame 合并\n",
    "hourly_probability_filled = pd.merge(possible_combinations, hourly_probability_df, left_on=[0, 1, 2], right_on=['begin_hour', 'level1', 'level2'], how='left')\n",
    "\n",
    "# 填充缺失值为0\n",
    "hourly_probability_filled['probability'].fillna(0, inplace=True)\n",
    "\n",
    "# 重新命名列名\n",
    "hourly_probability_filled.rename(columns={0: 'hour'}, inplace=True)\n",
    "# 重新命名列名\n",
    "hourly_probability_filled.rename(columns={1: 'l1'}, inplace=True)\n",
    "# 重新命名列名\n",
    "hourly_probability_filled.rename(columns={2: 'l2'}, inplace=True)\n",
    "\n",
    "# 打印结果\n",
    "print(hourly_probability_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c603d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 hourly_probability_filled 已经存在并且包含所有小时和组合的概率数据\n",
    "# 检查每个小时下，是否包含所有三种组合\n",
    "hours = range(24)\n",
    "combinations = [('1', '2'), ('1', '3'), ('2', '3')]\n",
    "\n",
    "# 补全缺失的数据\n",
    "for hour in hours:\n",
    "    for l1, l2 in combinations:\n",
    "        if not ((hourly_probability_filled['hour'] == hour) & \n",
    "                (hourly_probability_filled['l1'] == l1) & \n",
    "                (hourly_probability_filled['l2'] == l2)).any():\n",
    "            hourly_probability_filled = hourly_probability_filled.append(\n",
    "                {'begin_hour': hour, 'l1': l1, 'l2': l2, 'probability': 0.0},\n",
    "                ignore_index=True\n",
    "            )\n",
    "\n",
    "# 提取数据并创建新的 DataFrame\n",
    "level1_2 = hourly_probability_filled[(hourly_probability_filled['l1'] == '1') & (hourly_probability_filled['l2'] == '2')][['hour', 'probability']].rename(columns={'probability': 'probability_1_2'})\n",
    "level1_3 = hourly_probability_filled[(hourly_probability_filled['l1'] == '1') & (hourly_probability_filled['l2'] == '3')][['hour', 'probability']].rename(columns={'probability': 'probability_1_3'})\n",
    "level2_3 = hourly_probability_filled[(hourly_probability_filled['l1'] == '2') & (hourly_probability_filled['l2'] == '3')][['hour', 'probability']].rename(columns={'probability': 'probability_2_3'})\n",
    "\n",
    "# 合并到一个 DataFrame 中\n",
    "merged_df = pd.merge(level1_2, level1_3, on='hour', how='outer')\n",
    "merged_df = pd.merge(merged_df, level2_3, on='hour', how='outer')\n",
    "\n",
    "# 填充缺失值\n",
    "merged_df = merged_df.fillna(0)\n",
    "\n",
    "# 打印结果\n",
    "print(merged_df)\n",
    "\n",
    "# 将合并后的 DataFrame 保存为 CSV 文件\n",
    "csv_file_path = 'D:/研究生/毕业论文/数据/处理后数据/streamers_guanxi_between.csv'\n",
    "merged_df.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0caacaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fab37b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取数据\n",
    "hours = range(0,24)\n",
    "level1_2 = hourly_probability_filled[(hourly_probability_filled['l1'] == '1') & (hourly_probability_filled['l2'] == '2')]['probability']\n",
    "level1_3 = hourly_probability_filled[(hourly_probability_filled['l1'] == '1') & (hourly_probability_filled['l2'] == '3')]['probability']\n",
    "level2_3 = hourly_probability_filled[(hourly_probability_filled['l1'] == '2') & (hourly_probability_filled['l2'] == '3')]['probability']\n",
    "\n",
    "\n",
    "# 创建画布和子图\n",
    "fig, ax = plt.subplots(figsize=(12, 6), dpi=200)\n",
    "\n",
    "# 绘制观众数的对比图\n",
    "# 绘制图形\n",
    "ax.plot(hours, level1_2, label='level1_2', marker='o')\n",
    "ax.plot(hours, level1_3, label='level1_3', marker='x')\n",
    "ax.plot(hours, level2_3, label='level2_3', marker='s')\n",
    "ax.set_title('Hourly Probability by Level1 and Level2')\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6bb89455",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(level2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f909bc82",
   "metadata": {},
   "source": [
    "## 同等级之间的主播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbd14030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_probability(statistics):\n",
    "    result = defaultdict(lambda: defaultdict(float))\n",
    "    \n",
    "    for begin_hour in range(24):  # 假设 begin_hour 的范围是 0 到 23\n",
    "        for level in ['1', '2', '3']:  # 假设 level 的可能值\n",
    "            product_sets = []\n",
    "            for begin_date in statistics:\n",
    "                if begin_hour in statistics[begin_date] and level in statistics[begin_date][begin_hour]:\n",
    "                    product_sets.append(statistics[begin_date][begin_hour][level])\n",
    "            \n",
    "#             if product_sets:\n",
    "            probabilities = []\n",
    "            for set1, set2 in itertools.combinations(product_sets, 2):\n",
    "                intersection = set1.intersection(set2)\n",
    "                union = set1.union(set2)\n",
    "                if union:\n",
    "                    probability = len(intersection) / len(union)\n",
    "                else:\n",
    "                    probability = 0\n",
    "                probabilities.append(probability)\n",
    "\n",
    "            if probabilities:\n",
    "                average_probability = sum(probabilities) / len(probabilities)\n",
    "            else:\n",
    "                average_probability = 0\n",
    "\n",
    "            result[begin_hour][level] = average_probability\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65d181a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = calculate_average_probability(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "965a904e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ac2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_to_csv(result, filename):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['hour', 'level1', 'level2', 'level3']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for hour in result:\n",
    "            row = {'hour': hour}\n",
    "            for level in result[hour]:\n",
    "                row[f'level{level}'] = result[hour][level]\n",
    "            writer.writerow(row)\n",
    "\n",
    "# 调用保存函数\n",
    "save_to_csv(result, 'D:/研究生/毕业论文/数据/处理后数据/streamers_guanxi_on.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf51f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bad57e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}