{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import re\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import seaborn as sns\n",
    "from kneed import KneeLocator\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# # 指定字体\n",
    "# font_path = \"C:/Windows/Fonts/simsun.ttc\"  # SimSun字体路径\n",
    "# font_prop = font_manager.FontProperties(fname=font_path)\n",
    "\n",
    "# plt.rcParams[\"font.sans-serif\"] = [font_prop.get_name()]\n",
    "# plt.rcParams[\"axes.unicode_minus\"] = False  # 解决负号显示问题\n",
    "# plt.rcParams[\"font.size\"] = 10.5  # 设置五号字体大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置全局字体为 Times New Roman\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman']\n",
    "plt.rcParams['mathtext.fontset'] = 'custom'\n",
    "plt.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "plt.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "plt.rcParams['mathtext.bf'] = 'Times New Roman:bold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfa8d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置xtick和ytick的方向：in、out、inout\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ca52ce",
   "metadata": {},
   "source": [
    "删除非带货直播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"D:/研究生/毕业论文/数据/主播数据_3个月/livelinks_1000(2024.06.08-2024.09.05).csv\", \n",
    "             \"D:/研究生/毕业论文/数据/主播数据_3个月/livelinks_500-1000(2024.06.08-2024.09.05).csv\",\n",
    "             \"D:/研究生/毕业论文/数据/主播数据_3个月/livelinks_100-500(2024.06.08-2024.09.05).csv\",\n",
    "            \"D:/研究生/毕业论文/数据/主播数据_3个月/livelinks_10-100(2024.06.08-2024.09.05).csv\"\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9dcb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取xlsx文件\n",
    "df = pd.read_csv('D:/研究生/毕业论文/数据/主播数据_3个月/livelinks_1000(2024.06.08-2024.09.05).csv')\n",
    "# 筛选is_take_product为FALSE的行。gbk读取为布尔值，而不是字符串;如果不是gbk，则是字符串。\n",
    "filtered_df = df[df['is_take_product'] == 'False']\n",
    "# 获取要删除的room_id列表\n",
    "room_ids_to_delete = filtered_df['room_id']\n",
    "room_ids_to_delete = room_ids_to_delete.str.replace('\\t', '')\n",
    "data_folder = 'D:/研究生/毕业论文/数据/主播数据_3个月/meichangzhibodata_1000(2024.06.08-2024.09.05)'\n",
    "# 遍历文件夹中的文件\n",
    "for filename in os.listdir(data_folder):\n",
    "    # 提取文件名的前缀部分（去掉文件扩展名）\n",
    "    file_prefix = os.path.splitext(filename)[0]  # 获取不含扩展名的文件名前缀\n",
    "\n",
    "    # 检查提取的文件前缀是否在room_ids_to_delete中\n",
    "    if file_prefix in room_ids_to_delete.values:\n",
    "        # 构建完整的文件路径\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            # 删除文件\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "    else:\n",
    "        print(f\"Skipped file: {filename} (room_id not in list)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(room_ids_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf64bf",
   "metadata": {},
   "source": [
    "# 1.确认数据范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93310996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "# file_paths = [\"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_1000(2024.06.08-2024.09.05)/info.xlsx\", \n",
    "#              \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_500-1000(2024.06.08-2024.09.05)/info.xlsx\",\n",
    "#              \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_100-500(2024.06.08-2024.09.05)/info.xlsx\",\n",
    "#             \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_10-100(2024.06.08-2024.09.05)/info.xlsx\"\n",
    "#              ]\n",
    "file_paths = [\n",
    "             \"D:/研究生/论文/毕业论文/数据/主播数据_3个月/jieguo_100-500(2024.06.08-2024.09.05)/info.xlsx\",\n",
    "            \"D:/研究生/论文/毕业论文/数据/主播数据_3个月/jieguo_10-100(2024.06.08-2024.09.05)/info.xlsx\"\n",
    "             ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab109707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空DataFrame用于存储所有数据\n",
    "df_all = pd.DataFrame()\n",
    "for file_path in file_paths:\n",
    "    # 读取xlsx文件\n",
    "    df = pd.read_excel(file_path)\n",
    "    # 合并数据\n",
    "    df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "\n",
    "# 将 begin_time 和 room_finish_time 列的时间戳转换为 pandas 的日期时间格式\n",
    "df_all['begin_time'] = pd.to_datetime(df_all['begin_time'], unit='s')\n",
    "df_all['room_finish_time'] = pd.to_datetime(df_all['room_finish_time'], unit='s')\n",
    "\n",
    "# 将日期时间列的时区从 UTC 转换为北京时间\n",
    "df_all['begin_time'] = df_all['begin_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "df_all['room_finish_time'] = df_all['room_finish_time'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 提取日期作为新的列\n",
    "df_all['date'] = df_all['begin_time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b56b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取三个xlsx文件，假设文件名分别为file1.xlsx, file2.xlsx, file3.xlsx\n",
    "# file_multi_paths = [\"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_1000(2024.06.08-2024.09.05)/multi.xlsx\", \n",
    "#              \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_500-1000(2024.06.08-2024.09.05)/multi.xlsx\",\n",
    "#              \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_100-500(2024.06.08-2024.09.05)/multi.xlsx\",\n",
    "#               \"D:/研究生/毕业论文/数据/主播数据_3个月/jieguo_10-100(2024.06.08-2024.09.05)/multi.xlsx\"     ]\n",
    "file_multi_paths = [\n",
    "             \"D:/研究生/论文/毕业论文/数据/主播数据_3个月/jieguo_100-500(2024.06.08-2024.09.05)/multi.xlsx\",\n",
    "              \"D:/研究生/论文/毕业论文/数据/主播数据_3个月/jieguo_10-100(2024.06.08-2024.09.05)/multi.xlsx\"     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取multi.xlsx文件\n",
    "multi_df = pd.concat([pd.read_excel(file_path) for file_path in file_multi_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据直播ID合并两个DataFrame\n",
    "merged_df = pd.merge(df_all, multi_df, on='room_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcec4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表，用于存储格式有问题的 room_id\n",
    "invalid_room_ids = []\n",
    "\n",
    "# 遍历 merged_df 中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 获取当前行的 room_id 和 charts 列数据\n",
    "    room_id = row['room_id']\n",
    "    charts_data = row['charts']\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    charts_data = charts_data.replace(\"'\", \"\\\"\")\n",
    "    \n",
    "    try:\n",
    "        # 使用 json.loads() 将字符串解析为 JSON 对象\n",
    "        charts_list = json.loads(charts_data)\n",
    "    except json.JSONDecodeError:\n",
    "        # 如果解析失败，则记录该行的 room_id\n",
    "        invalid_room_ids.append(room_id)\n",
    "# 打印格式有问题的 room_id\n",
    "print(\"格式有问题的 room_id：\", len(invalid_room_ids))\n",
    "print(\"格式有问题的 room_id：\", invalid_room_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e69f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除格式有问题的 room_id 对应的行\n",
    "merged_df = merged_df[~merged_df['room_id'].isin(invalid_room_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个空列表，用于存储展开后的数据\n",
    "expanded_data_list = []\n",
    "\n",
    "# 遍历 merged_df 中的每一行\n",
    "for index, row in merged_df.iterrows():\n",
    "    # 获取当前行的 room_id 和 charts 列数据\n",
    "    room_id = row['room_id']\n",
    "    # follower = row['follower_count']\n",
    "    charts_data = row['charts']\n",
    "    \n",
    "    # 将单引号替换为双引号\n",
    "    charts_data = charts_data.replace(\"'\", \"\\\"\")\n",
    "    \n",
    "    # 使用 json.loads() 将字符串解析为 JSON 对象\n",
    "    charts_list = json.loads(charts_data)\n",
    "    \n",
    "    # 遍历每个直播间的 charts 数据\n",
    "    for chart in charts_list:\n",
    "        # 将每个字典添加到列表中，并添加 room_id\n",
    "        chart['room_id'] = room_id\n",
    "        # chart['follower'] = follower\n",
    "        expanded_data_list.append(chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27902dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将列表转换为 DataFrame\n",
    "expanded_data = pd.DataFrame(expanded_data_list)\n",
    "\n",
    "# 将 time_node 列转换为日期时间类型\n",
    "expanded_data['time_node'] = pd.to_datetime(expanded_data['time_node'], unit='s')\n",
    "\n",
    "expanded_data['time_node'] = expanded_data['time_node'].dt.tz_localize('UTC').dt.tz_convert('Asia/Shanghai')\n",
    "\n",
    "# 根据 time_node 列提取日期\n",
    "expanded_data['date'] = expanded_data['time_node'].dt.date\n",
    "\n",
    "# 提取小时\n",
    "expanded_data['hour'] = expanded_data['time_node'].dt.hour\n",
    "\n",
    "# 提取分钟\n",
    "expanded_data['minute'] = expanded_data['time_node'].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bd2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出需要增加的列名\n",
    "columns_to_increment = ['real_time_user', 'leave_user', 'user_count']\n",
    "\n",
    "# 将这些列的数据全部加 1\n",
    "expanded_data[columns_to_increment] = expanded_data[columns_to_increment] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276450e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes(filtered_data, time_interval='5T', save_path=None):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // int(time_interval[:-1]) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages['time_period_str'] = monthly_averages['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages['time_period'] = pd.to_datetime(monthly_averages['hour'].astype(str) + ':' + monthly_averages['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(20, 4))\n",
    "\n",
    "    # 绘制特征数据\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['real_time_user'], marker='o', label='进场用户', color='#4169e0')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['leave_user'], marker='x', label='离线用户', color='#ff0000')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['user_count'], marker='s', label='在线用户', color='#00cdd0')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    # ax.set_title(f'每隔{int(time_interval[:-1])}分钟的特征变化', fontweight='bold')\n",
    "    ax.set_ylabel('数量', fontweight='bold', fontproperties=font_prop,fontsize=12)\n",
    "    ax.legend()\n",
    "\n",
    "    # 设置 x 轴标签\n",
    "    ax.set_xlabel('时间区间', fontproperties=font_prop,fontsize=12)\n",
    "\n",
    "    # 设置 x 轴刻度\n",
    "    # 设置 x 轴刻度为每小时一个刻度\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    # # 自动旋转 x 轴刻度标签\n",
    "    # plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ba2a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes(filtered_data, time_interval='5T', save_path=None):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // int(time_interval[:-1]) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages['time_period_str'] = monthly_averages['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages['time_period'] = pd.to_datetime(monthly_averages['hour'].astype(str) + ':' + monthly_averages['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "    # 绘制特征数据\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['real_time_user'], marker='o', label='进场用户', color='#4169e0')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['leave_user'], marker='x', label='离线用户', color='#ff0000')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['user_count'], marker='s', label='在线用户', color='#00cdd0')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_ylabel('数量', fontweight='bold', fontproperties=font_prop, fontsize=20)\n",
    "    ax.legend()\n",
    "\n",
    "    # 设置 x 轴标签\n",
    "    ax.set_xlabel('时间区间', fontproperties=font_prop, fontsize=20)\n",
    "\n",
    "    # 设置 x 轴刻度\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=4))  # 每两个小时一个刻度\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    # 增加字体大小\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(20)  # 设置x轴刻度字体大小\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontsize(20)  # 设置y轴刻度字体大小\n",
    "    \n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=5))  # 设置y轴刻度数量\n",
    "    \n",
    "    # 调整图例\n",
    "    ax.legend(fontsize=20, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=3)  # 在正上方\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a02f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes_1(filtered_data, time_interval='5T', save_path=None):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // int(time_interval[:-1]) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages['time_period_str'] = monthly_averages['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages['time_period'] = pd.to_datetime(monthly_averages['hour'].astype(str) + ':' + monthly_averages['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "    # 绘制特征数据\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['real_time_user'], marker='o', label='New Users', color='#4169e0')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['leave_user'], marker='x', label='Offline Users', color='#ff0000')\n",
    "    ax.plot(monthly_averages['time_period'], monthly_averages['user_count'], marker='s', label='Online Users', color='#00cdd0')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    ax.set_ylabel('Quantity', fontsize=20)\n",
    "    ax.legend()\n",
    "\n",
    "    # 设置 x 轴标签\n",
    "    ax.set_xlabel('Time Interval', fontsize=20)\n",
    "\n",
    "    # 设置 x 轴刻度\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=4))  # 每两个小时一个刻度\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    # 增加字体大小\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(20)  # 设置x轴刻度字体大小\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontsize(20)  # 设置y轴刻度字体大小\n",
    "    \n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=5))  # 设置y轴刻度数量\n",
    "    \n",
    "    # 调整图例\n",
    "    ax.legend(fontsize=20, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=3)  # 在正上方\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes(expanded_data, time_interval='1T', save_path='D:/研究生/毕业论文/代码/网络构建/直播平台网络模型/图片/时间范围_1.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes(expanded_data, time_interval='2T', save_path='D:/研究生/毕业论文/代码/网络构建/直播平台网络模型/图片/时间范围_2.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b51a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes(expanded_data, time_interval='3T', save_path='D:/研究生/毕业论文/草稿/图片/时间范围_3.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes(expanded_data, time_interval='10T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31275014",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes(expanded_data, time_interval='60T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_1(expanded_data, time_interval='3T', save_path='D:/研究生/论文/期刊论文/小论文1/草稿/图片/time_interval_3.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eab2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb5e746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cdfd5a2",
   "metadata": {},
   "source": [
    "确认好数据的范围为：19：00-01：00."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132e01e",
   "metadata": {},
   "source": [
    "# 2.确认窗口大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897f26b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据筛选，只需要晚上时间段的直播\n",
    "filtered_data = expanded_data[expanded_data['hour'].isin([19, 20, 21, 22, 23, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27862575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes_part(filtered_data, time_interval='5T', save_path=None):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // int(time_interval[:-1]) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 你想要的小时顺序\n",
    "    desired_order = [19, 20, 21, 22, 23, 0, 1]\n",
    "\n",
    "    # 将 hour 列转换为 Categorical 类型，并指定排序顺序\n",
    "    monthly_averages['hour'] = pd.Categorical(monthly_averages['hour'], categories=desired_order, ordered=True)\n",
    "\n",
    "    # 根据 hour 列和 time_period 列对 DataFrame 进行排序\n",
    "    monthly_averages_sorted = monthly_averages.sort_values(['hour', 'time_period'])\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages_sorted['time_period_str'] = monthly_averages_sorted['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages_sorted['time_period'] = pd.to_datetime(monthly_averages_sorted['hour'].astype(str) + ':' + monthly_averages_sorted['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "    # 对于 hour 为 0 或 1，日期加一天\n",
    "    monthly_averages_sorted.loc[monthly_averages_sorted['hour'].isin([0, 1]), 'time_period'] = \\\n",
    "        monthly_averages_sorted['time_period'] + pd.DateOffset(days=1)\n",
    "\n",
    "    # 重置索引以确保索引与排序后的顺序相匹配\n",
    "    monthly_averages_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # print(monthly_averages_sorted)\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "    # 绘制特征数据\n",
    "    ax.plot(monthly_averages_sorted['time_period'],monthly_averages_sorted['real_time_user'], marker='o', label='进场用户', color='#4169e0')\n",
    "    ax.plot(monthly_averages_sorted['time_period'], monthly_averages_sorted['leave_user'], marker='x', label='离线用户', color='#ff0000')\n",
    "    ax.plot(monthly_averages_sorted['time_period'], monthly_averages_sorted['user_count'], marker='s', label='在线用户', color='#00cdd0')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    # ax.set_title(f'每隔{int(time_interval[:-1])}分钟的特征变化', fontweight='bold')\n",
    "    ax.set_ylabel('数量', fontweight='bold', fontproperties=font_prop,fontsize=20)\n",
    "    ax.legend()\n",
    "\n",
    "    # 添加文本\n",
    "    ax.text(x=0.5, y=-0.1, s=f'(3)每隔{int(time_interval[:-1])}分钟的特征变化', ha='center', va='center', fontsize=20, transform=ax.transAxes)\n",
    "\n",
    "    # 设置 x 轴标签\n",
    "    ax.set_xlabel('时间区间', fontproperties=font_prop,fontsize=20,labelpad=30)\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=5))  # 设置y轴刻度数量\n",
    "\n",
    "    # 增加字体大小\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(20)  # 设置x轴刻度字体大小\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontsize(20)  # 设置y轴刻度字体大小\n",
    "    \n",
    "    # 调整图例\n",
    "    ax.legend(fontsize=20, loc='upper center', bbox_to_anchor=(0.5, 1), ncol=3)  # 在正上方\n",
    "\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83736ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_changes_part_1(filtered_data, time_interval='5T', save_path=None):\n",
    "    \"\"\"\n",
    "    绘制每个等级的特征变化图，根据指定的时间间隔。\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_data (pd.DataFrame): 包含数据的 DataFrame。\n",
    "    - time_interval (str): 时间间隔，格式为 '5T', '10T', '30T' 等。\n",
    "    - save_path (str): 图像保存路径。\n",
    "    \"\"\"\n",
    "    # 创建数据副本，避免链式赋值问题\n",
    "    filtered_data_n = filtered_data.copy()\n",
    "    # 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "    filtered_data_n.loc[:, 'time_period'] = filtered_data_n['minute'] // int(time_interval[:-1]) * int(time_interval[:-1])\n",
    "\n",
    "    # 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "    average_features = filtered_data_n.groupby(['date', 'hour', 'time_period', 'room_id'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "    # 将同等级的直播间进行求和\n",
    "    summed_features = average_features.groupby(['date', 'hour', 'time_period'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "    # 按月计算每个特征的平均值\n",
    "    monthly_averages = summed_features.groupby(['hour', 'time_period']).agg({\n",
    "        'real_time_user': 'mean',\n",
    "        'leave_user': 'mean',\n",
    "        'user_count': 'mean'\n",
    "    }).reset_index()\n",
    "\n",
    "    # 你想要的小时顺序\n",
    "    desired_order = [19, 20, 21, 22, 23, 0, 1]\n",
    "\n",
    "    # 将 hour 列转换为 Categorical 类型，并指定排序顺序\n",
    "    monthly_averages['hour'] = pd.Categorical(monthly_averages['hour'], categories=desired_order, ordered=True)\n",
    "\n",
    "    # 根据 hour 列和 time_period 列对 DataFrame 进行排序\n",
    "    monthly_averages_sorted = monthly_averages.sort_values(['hour', 'time_period'])\n",
    "\n",
    "    # 将 'time_period' 转换为实际时间格式\n",
    "    monthly_averages_sorted['time_period_str'] = monthly_averages_sorted['time_period'].astype(int).astype(str).str.zfill(2) + ':00'\n",
    "    monthly_averages_sorted['time_period'] = pd.to_datetime(monthly_averages_sorted['hour'].astype(str) + ':' + monthly_averages_sorted['time_period_str'], format='%H:%M:%S')\n",
    "\n",
    "    # 对于 hour 为 0 或 1，日期加一天\n",
    "    monthly_averages_sorted.loc[monthly_averages_sorted['hour'].isin([0, 1]), 'time_period'] = \\\n",
    "        monthly_averages_sorted['time_period'] + pd.DateOffset(days=1)\n",
    "\n",
    "    # 重置索引以确保索引与排序后的顺序相匹配\n",
    "    monthly_averages_sorted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # print(monthly_averages_sorted)\n",
    "\n",
    "    # 创建图形\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "    # 绘制特征数据\n",
    "    ax.plot(monthly_averages_sorted['time_period'],monthly_averages_sorted['real_time_user'], marker='o', label='New Users', color='#4169e0')\n",
    "    ax.plot(monthly_averages_sorted['time_period'], monthly_averages_sorted['leave_user'], marker='x', label='Offline Users', color='#ff0000')\n",
    "    ax.plot(monthly_averages_sorted['time_period'], monthly_averages_sorted['user_count'], marker='s', label='Online Users', color='#00cdd0')\n",
    "\n",
    "    # 设置标题和标签\n",
    "    # ax.set_title(f'每隔{int(time_interval[:-1])}分钟的特征变化', fontweight='bold')\n",
    "    ax.set_ylabel('Quantity',fontsize=20)\n",
    "    ax.legend()\n",
    "\n",
    "    # 添加文本\n",
    "    ax.text(x=0.5, y=-0.1, s=f'(c) Features Change Every {int(time_interval[:-1])} Minutes', ha='center', va='center', fontsize=20, transform=ax.transAxes)\n",
    "\n",
    "    # 设置 x 轴标签\n",
    "    ax.set_xlabel('Time Interval',fontsize=20,labelpad=30)\n",
    "\n",
    "    ax.xaxis.set_major_locator(mdates.HourLocator(interval=1))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=5))  # 设置y轴刻度数量\n",
    "\n",
    "    # 增加字体大小\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(20)  # 设置x轴刻度字体大小\n",
    "    for label in ax.get_yticklabels():\n",
    "        label.set_fontsize(20)  # 设置y轴刻度字体大小\n",
    "    \n",
    "    # 调整图例\n",
    "    ax.legend(fontsize=20, loc='upper right', ncol=1)  # 在右上方\n",
    "\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图为文件\n",
    "    plt.savefig(save_path)\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bcd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='1T',save_path='D:/研究生/毕业论文/代码/网络构建/直播平台网络模型/图片/时间粒度_1.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d614bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='2T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8341e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='3T',save_path='D:/研究生/毕业论文/草稿/图片/时间粒度_3.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='10T',save_path='D:/研究生/毕业论文/草稿/图片/时间粒度_10.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e966ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='12T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f59df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part(filtered_data, time_interval='60T',save_path='D:/研究生/毕业论文/草稿/图片/时间粒度_60.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c102926a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34577fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part_1(filtered_data, time_interval='1T',save_path='D:/研究生/论文/期刊论文/小论文1/新期刊/草稿/figures/time_granularity_1.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part_1(filtered_data, time_interval='10T',save_path='D:/研究生/论文/期刊论文/小论文1/新期刊/草稿/figures/time_granularity_10.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd77ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_changes_part_1(filtered_data, time_interval='20T',save_path='D:/研究生/论文/期刊论文/小论文1/新期刊/草稿/figures/time_granularity_20.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1686880",
   "metadata": {},
   "source": [
    "最终确认窗口大小设置为10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49241226",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f'./处理数据/filtered_data.csv'\n",
    "filtered_data.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0d635c",
   "metadata": {},
   "source": [
    "# 3.确认主播等级划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据副本，避免链式赋值问题\n",
    "filtered_data_n = filtered_data.copy()\n",
    "# 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "# 同时获取每组 follower_count 的最大值\n",
    "average_features = filtered_data_n.groupby(['room_id']).agg({\n",
    "    'real_time_user': 'mean',\n",
    "    'leave_user': 'mean',\n",
    "    'user_count': 'mean',\n",
    "    'follower_count': 'max',\n",
    "    \"like_count\":'max'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4095d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb41df",
   "metadata": {},
   "source": [
    "粉丝数小于10w可能是后面增大到10w造成的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 霍普金斯统计量的计算函数\n",
    "def hopkins(X):\n",
    "    d = X.shape[1]  # 特征数量:3\n",
    "    n = len(X)  # 样本数量:11516\n",
    "    m = int(0.1 * n)  # 采样数量 (一般取样本数的10%):1152\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(X)  # 最近邻计算\n",
    "\n",
    "    random_sample_indices = random.sample(range(0, n), m)  # 从原数据中随机采样m个点\n",
    "    u_distances = []  # 原数据点的最近邻距离\n",
    "    w_distances = []  # 随机生成点的最近邻距离\n",
    "\n",
    "    # 计算原数据点的最近邻距离\n",
    "    for index in random_sample_indices:\n",
    "        u_distances.append(\n",
    "            nbrs.kneighbors([X[index]], 2, return_distance=True)[0][0][1]\n",
    "        )\n",
    "\n",
    "    # 随机生成点的最近邻距离\n",
    "    for _ in range(m):\n",
    "        random_point = [random.uniform(min(X[:, i]), max(X[:, i])) for i in range(d)]\n",
    "        w_distances.append(nbrs.kneighbors([random_point], 1, return_distance=True)[0][0][0])\n",
    "\n",
    "    # 计算霍普金斯统计量\n",
    "    H = sum(w_distances) / (sum(w_distances) + sum(u_distances))\n",
    "    return H\n",
    "\n",
    "# 将数据转换为 numpy 数组\n",
    "features = average_features[['real_time_user', 'leave_user', 'user_count']].values\n",
    "\n",
    "# 计算霍普金斯统计量\n",
    "hopkins_value = hopkins(features)\n",
    "print(f\"霍普金斯统计量: {hopkins_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32bc47",
   "metadata": {},
   "source": [
    "数据具有显著的聚类趋势，继续进行聚类分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8400032",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21741b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6cf2635",
   "metadata": {},
   "source": [
    "## 3.1 kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd4194",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "# silhouette_scores = []\n",
    "k_values = range(1, 11)  # 通常可以尝试 2 到 10 个聚类\n",
    "# 轮廓系数需要至少两个聚类才能计算。如果只有一个聚类，那么就没有其他聚类来比较，因此无法计算轮廓系数。\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    # silhouette_scores.append(silhouette_score(features, kmeans.labels_))\n",
    "\n",
    "# 设置 Matplotlib 使用 ieee 样式\n",
    "with plt.style.context(['ieee', 'no-latex']):\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # 绘制每个时刻的训练集大小\n",
    "    plt.plot(k_values, sse, marker='o', linestyle='-', color='#fb0200', markersize=5,  linewidth=1)\n",
    "\n",
    "    # 添加标签和标题\n",
    "    plt.xlabel('簇数', fontproperties=font_prop,fontsize=14)\n",
    "    plt.ylabel('误差平方和', fontproperties=font_prop,fontsize=14)\n",
    "#     plt.title('Training Set Size Over Time', fontsize=16, fontweight='bold')\n",
    "#     plt.legend()\n",
    "\n",
    "    # 调整坐标轴刻度文本的大小\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    # 设置网格线\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图为PDF文件\n",
    "    plt.savefig('D:/研究生/毕业论文/草稿/图片/拐点图.svg')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# # 绘制肘部图\n",
    "# plt.figure(figsize=(8, 6))\n",
    "\n",
    "# # 绘制SSE图\n",
    "# # plt.subplot(1, 2, 1)\n",
    "# plt.plot(k_values, sse, marker='o')\n",
    "# plt.xlabel('簇数', fontproperties=font_prop,fontsize=12)\n",
    "# plt.ylabel('误差平方和', fontproperties=font_prop,fontsize=12)\n",
    "# # plt.title('Elbow Method for Optimal k')\n",
    "# plt.grid(True)\n",
    "\n",
    "# # # 绘制轮廓系数图\n",
    "# # plt.subplot(1, 2, 2)\n",
    "# # plt.plot(k_values, silhouette_scores, marker='o')\n",
    "# # plt.xlabel('Number of Clusters (k)')\n",
    "# # plt.ylabel('Silhouette Score')\n",
    "# # plt.title('Silhouette Scores for Optimal k')\n",
    "# # plt.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # 保存图形为 PDF\n",
    "# plt.savefig('D:/研究生/毕业论文/代码/网络构建/直播平台网络模型/图片/拐点图.svg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "sse = []\n",
    "# silhouette_scores = []\n",
    "k_values = range(1, 11)  # 通常可以尝试 2 到 10 个聚类\n",
    "# 轮廓系数需要至少两个聚类才能计算。如果只有一个聚类，那么就没有其他聚类来比较，因此无法计算轮廓系数。\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(features)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    # silhouette_scores.append(silhouette_score(features, kmeans.labels_))\n",
    "\n",
    "# 设置 Matplotlib 使用 ieee 样式\n",
    "with plt.style.context(['ieee', 'no-latex']):\n",
    "    # 创建图形\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # 绘制每个时刻的训练集大小\n",
    "    plt.plot(k_values, sse, marker='o', linestyle='-', color='#fb0200', markersize=5,  linewidth=1)\n",
    "\n",
    "    # 添加标签和标题\n",
    "    plt.xlabel('Clusters',fontsize=14)\n",
    "    plt.ylabel('Sum of Squared Errors',fontsize=14)\n",
    "#     plt.title('Training Set Size Over Time', fontsize=16, fontweight='bold')\n",
    "#     plt.legend()\n",
    "\n",
    "    # 调整坐标轴刻度文本的大小\n",
    "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "    # 设置网格线\n",
    "#     plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图为PDF文件\n",
    "    plt.savefig('D:/研究生/论文/期刊论文/小论文1/草稿/图片/inflection_point.eps')\n",
    "\n",
    "    # 显示图形\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdfb7e",
   "metadata": {},
   "source": [
    "在绘制的肘部图中，寻找 SSE 曲线的拐点，即曲线从快速下降转为缓慢下降的位置。\n",
    "\n",
    "该拐点的 k 值就是推荐的最佳聚类数目。\n",
    "\n",
    "k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b3f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置聚类数目，可以通过肘部法则或轮廓系数来选择最佳的k值\n",
    "n_clusters = 2  # 这里假设为3，根据实际需要调整\n",
    "\n",
    "# 使用 KMeans 进行聚类\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "average_features['cluster'] = kmeans.fit_predict(features)\n",
    "\n",
    "# 查看每个聚类中的样本数量\n",
    "print(average_features['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 0]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 1]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74f17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 2]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502060ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 3]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404b7eb6",
   "metadata": {},
   "source": [
    "效果还可以"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41eefb",
   "metadata": {},
   "source": [
    "## 3.2 Birch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15be141",
   "metadata": {},
   "source": [
    "层次聚类的典型代表，天生就是为处理超大规模数据集而设计的，它利用一个树结构来快速聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c8a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "\n",
    "# 创建 BIRCH 模型，指定簇的数量\n",
    "birch_model = Birch(n_clusters=2, threshold=0.9)\n",
    "\n",
    "# 训练模型\n",
    "birch_model.fit(features)\n",
    "\n",
    "# 获取聚类标签\n",
    "labels = birch_model.predict(features)\n",
    "\n",
    "# 将聚类标签添加到数据中\n",
    "average_features['cluster'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1961f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每个聚类中的样本数量\n",
    "print(average_features['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92144520",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 0]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a0f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 1]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69909f7e",
   "metadata": {},
   "source": [
    "数据不标准化比标准化更好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e1468b",
   "metadata": {},
   "source": [
    "## 3.3 DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d22e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算距离矩阵\n",
    "distance_matrix = pairwise_distances(features, metric='euclidean')\n",
    "\n",
    "# 选择 k 值\n",
    "k = 5  # 可以尝试不同的 k 值来观察效果\n",
    "\n",
    "# 计算 k 距离\n",
    "nbrs = NearestNeighbors(n_neighbors=k).fit(features)\n",
    "distances, _ = nbrs.kneighbors(features)\n",
    "k_distances = np.sort(distances[:, -1])\n",
    "\n",
    "# 绘制 k 距离曲线\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(np.arange(len(k_distances)), k_distances, marker='o', linestyle='-')\n",
    "plt.title('k-Distance Graph')\n",
    "plt.xlabel('Points Sorted by Distance')\n",
    "plt.ylabel(f'{k}th Nearest Neighbor Distance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3642791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Kneedle 算法查找拐点\n",
    "kneedle = KneeLocator(\n",
    "    np.arange(len(k_distances)), k_distances, curve='convex', direction='increasing'\n",
    ")\n",
    "\n",
    "# 获取拐点位置\n",
    "knee_point = kneedle.knee\n",
    "knee_value = k_distances[knee_point]\n",
    "\n",
    "# 标注拐点\n",
    "plt.axvline(x=knee_point, color='r', linestyle='--', label=f'Elbow at index {knee_point}')\n",
    "plt.axhline(y=knee_value, color='r', linestyle='--', label=f'k-Distance = {knee_value:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"拐点位置: {knee_point}, 拐点对应的 k 距离值: {knee_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# 创建 DBSCAN 模型\n",
    "dbscan_model = DBSCAN(eps=789, min_samples=6)  # 根据数据和需求调整 eps 和 min_samples\n",
    "\n",
    "# 训练模型\n",
    "labels = dbscan_model.fit_predict(features)\n",
    "\n",
    "# 将聚类标签添加到数据中\n",
    "average_features['cluster'] = labels\n",
    "#过滤噪声点：因为 DBSCAN 的噪声点被标记为 -1，我们在计算轮廓系数时忽略这些点。\n",
    "\n",
    "# 查看每个聚类中的样本数量\n",
    "print(average_features['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab847b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == 0]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = average_features[average_features['cluster'] == -1]\n",
    "cluster_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ca9d9",
   "metadata": {},
   "source": [
    "效果不好，数据量差异太大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ee99f5",
   "metadata": {},
   "source": [
    "总结：KMEANS最好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0978b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195ef77",
   "metadata": {},
   "source": [
    "## 3.4 平均聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def balanced_kmeans(X, k, max_iterations=100):\n",
    "    # 初始化质心位置\n",
    "    centroids = initialize_centroids(X, k)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # 赋值步骤\n",
    "        # 计算边权重（这里可以是距离或相似度等）\n",
    "        edge_weights = compute_edge_weights(X, centroids)\n",
    "        \n",
    "        # 解决分配问题\n",
    "        assignments = solve_assignment_problem(edge_weights)\n",
    "        \n",
    "        # 更新步骤\n",
    "        new_centroids = update_centroids(X, assignments, k)\n",
    "        \n",
    "        # 检查质心位置是否变化\n",
    "        if np.all(centroids == new_centroids):\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return assignments\n",
    "\n",
    "def initialize_centroids(X, k):\n",
    "    # 随机选择初始质心\n",
    "    indices = np.random.choice(X.shape[0], k, replace=False)\n",
    "    return X[indices]\n",
    "\n",
    "def compute_edge_weights(X, centroids):\n",
    "    # 计算边权重，这里使用欧氏距离\n",
    "    n_samples = X.shape[0]\n",
    "    k = centroids.shape[0]\n",
    "    edge_weights = np.zeros((n_samples, n_samples))\n",
    "    \n",
    "    # 计算每个样本点到每个质心的距离\n",
    "    distances = np.zeros((n_samples, k))\n",
    "    for j in range(k):\n",
    "        distances[:, j] = np.linalg.norm(X - centroids[j], axis=1)\n",
    "\n",
    "    # 填充边权重矩阵\n",
    "    for a in range(n_samples):\n",
    "        centroid_index = (a % k)  # 使用 a mod k\n",
    "        edge_weights[a, :] = distances[:, centroid_index]\n",
    "    \n",
    "    return edge_weights\n",
    "\n",
    "\n",
    "def solve_assignment_problem(edge_weights):\n",
    "    # 解决分配问题，使用匈牙利算法\n",
    "    row_ind, col_ind = linear_sum_assignment(edge_weights)\n",
    "    assignments = np.zeros(edge_weights.shape[0], dtype=int)\n",
    "    assignments[row_ind] = col_ind\n",
    "    return assignments\n",
    "\n",
    "def update_centroids(X, assignments, k):\n",
    "    # 更新质心位置\n",
    "    new_centroids = np.zeros((k, X.shape[1]))\n",
    "    \n",
    "    for i in range(k):\n",
    "        assigned_points = X[assignments == i]  # 选取分配到簇 i 的数据点\n",
    "        if len(assigned_points) > 0:\n",
    "            new_centroids[i] = np.mean(assigned_points, axis=0)  # 计算均值\n",
    "        else:\n",
    "            new_centroids[i] = np.random.rand(X.shape[1])  # 如果没有数据点，随机初始化质心\n",
    "    \n",
    "    return new_centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    X = features  \n",
    "    k = 3  # 簇的数量\n",
    "    \n",
    "    # 运行平衡K-means算法\n",
    "    assignments = balanced_kmeans(X, k)\n",
    "    print(\"Cluster assignments:\", assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a24f2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac2a3d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd20c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b57d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e837a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2da2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93425fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d128c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaaa5f75",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab14a72d",
   "metadata": {},
   "source": [
    "# 4.处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = '10T'\n",
    "# 创建数据副本，避免链式赋值问题\n",
    "filtered_data_n_1 = filtered_data.copy()\n",
    "# 从 average_features 中只选择 'room_id' 和 'cluster' 列\n",
    "average_features_subset = average_features[['room_id', 'cluster']]\n",
    "# 按 'room_id' 列进行合并，只将 cluster 列添加到 filtered_data_n_1 中\n",
    "merged_data = pd.merge(filtered_data_n_1, average_features_subset, on='room_id', how='left')\n",
    "\n",
    "# 使用 .loc 方法进行赋值，避免链式赋值警告\n",
    "merged_data.loc[:, 'time_period'] = merged_data['minute'] // (int(time_interval[:-1])) * int(time_interval[:-1])\n",
    "\n",
    "# 计算每个直播间在每个时间段的平均特征，仅包括特定的特征\n",
    "average_features_1 = merged_data.groupby(['date', 'hour', 'time_period', 'room_id', 'cluster'])[['real_time_user', 'leave_user', 'user_count']].mean().reset_index()\n",
    "\n",
    "# 对每个小时内所有直播间的实时用户数取整，然后再求和\n",
    "average_features_1['real_time_user'] = average_features_1['real_time_user'].round().astype(int)\n",
    "average_features_1['leave_user'] = average_features_1['leave_user'].round().astype(int)\n",
    "average_features_1['user_count'] = average_features_1['user_count'].round().astype(int)\n",
    "\n",
    "# 将同等级的直播间进行求和\n",
    "summed_features = average_features_1.groupby(['date', 'hour', 'time_period', 'cluster'])[['real_time_user', 'leave_user', 'user_count']].sum().reset_index()\n",
    "\n",
    "# 获取所有唯一的等级\n",
    "levels = summed_features['cluster'].unique()\n",
    "\n",
    "# 对每个等级的数据进行提取\n",
    "for level in levels:\n",
    "    # 提取当前等级的数据\n",
    "    level_data = summed_features[summed_features['cluster'] == level]\n",
    "\n",
    "    # 删除不需要的列\n",
    "    level_data = level_data.drop(columns=['cluster'])\n",
    "    \n",
    "    # 保存到 CSV 文件\n",
    "    output_file = f'./处理数据/hourly_stats_level_{level}.csv'\n",
    "    level_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved data for level {level} to {output_file}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c2d867",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './处理数据'\n",
    "\n",
    "# 处理每个级别的数据\n",
    "for level in [0,1]:  # 假设你有4个级别，调整为实际需要的级别\n",
    "    # 构建文件名\n",
    "    file_name = f'hourly_stats_level_{level}.csv'\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    \n",
    "    # 读取数据\n",
    "    hourly_stats = pd.read_csv(file_path)\n",
    "    \n",
    "    # 重命名列\n",
    "    hourly_stats.columns = ['date', 'hour', 'time_period', 'real_time_user', 'leave_user', 'user_count']\n",
    "\n",
    "    # 确保数据按照日期、小时和时间段排序\n",
    "    hourly_stats = hourly_stats.sort_values(by=['date', 'hour', 'time_period'])\n",
    "    \n",
    "    # 创建匹配后的数据\n",
    "    merged_data = pd.DataFrame()\n",
    "\n",
    "    # 定义时间间隔的步长\n",
    "    time_intervals = list(range(0, 60, 10))  # 每隔10分钟\n",
    "    for i in range(len(time_intervals) - 1):\n",
    "        # 当前时间段和下一个时间段的分钟数\n",
    "        current_time_period = time_intervals[i]\n",
    "        next_time_period = time_intervals[i + 1]\n",
    "        \n",
    "        # 获取当前时间段和下一时间段的数据\n",
    "        current_time_data = hourly_stats[hourly_stats['time_period'] == current_time_period]\n",
    "        next_time_data = hourly_stats[hourly_stats['time_period'] == next_time_period]\n",
    "        \n",
    "        # 合并数据，确保同一天、同一小时的数据匹配\n",
    "        merged_time_data_1 = pd.merge(current_time_data, next_time_data, on=['date', 'hour'], suffixes=('', '_t'))\n",
    "\n",
    "        # 只保留匹配成功的行\n",
    "        if not merged_time_data_1.empty:\n",
    "            merged_data = pd.concat([merged_data, merged_time_data_1], axis=0)\n",
    "    \n",
    "    # 当前时间段和下一个时间段的分钟数\n",
    "    current_time_period = time_intervals[5]\n",
    "    next_time_period = time_intervals[0]\n",
    "\n",
    "    # 获取当前时间段和下一时间段的数据\n",
    "    current_time_data = hourly_stats[hourly_stats['time_period'] == current_time_period]\n",
    "    next_time_data = hourly_stats[hourly_stats['time_period'] == next_time_period].copy()\n",
    "\n",
    "    # 根据情况调整 next_time_data 的 hour\n",
    "    # 合并跨日数据\n",
    "    merged_time_data_2 = pd.DataFrame()  # 初始化空数据框\n",
    "    merged_time_data_3 = pd.DataFrame()  # 初始化空数据框\n",
    "\n",
    "    # 按照当前时间数据的 hour 分组处理\n",
    "    grouped_current_time = current_time_data.groupby('hour', observed=False)\n",
    "    print(grouped_current_time)\n",
    "    for hour, group in grouped_current_time:\n",
    "        if hour == 1:\n",
    "            # 如果 hour == 1，跳过该组数据\n",
    "            continue\n",
    "        elif hour == 23:\n",
    "            # 获取下一个小时的数据\n",
    "            next_hour_data = next_time_data[next_time_data['hour'] == 0]\n",
    "            if not next_hour_data.empty:\n",
    "                # 合并数据\n",
    "                merged_time_data_2 = pd.merge(group, next_hour_data, on=['date'], suffixes=('', '_t'))\n",
    "                if not merged_time_data_2.empty:\n",
    "                    merged_data = pd.concat([merged_data, merged_time_data_2], axis=0)\n",
    "        else:\n",
    "            # 获取当前小时 + 1 的下一时间段数据\n",
    "            next_hour = hour + 1\n",
    "            next_hour_data = next_time_data[next_time_data['hour'] == next_hour]\n",
    "            if not next_hour_data.empty:\n",
    "                # 合并数据\n",
    "                merged_time_data_3 = pd.merge(\n",
    "                    group, next_hour_data, \n",
    "                    on=['date'], suffixes=('', '_t')\n",
    "                )\n",
    "                # 只保留匹配成功的行\n",
    "                if not merged_time_data_3.empty:\n",
    "                    merged_data = pd.concat([merged_data, merged_time_data_3], axis=0)\n",
    "    \n",
    "    # 丢弃不必要的列（如 'time_period_t' 列）\n",
    "    merged_data = merged_data.drop(columns=['time_period_t'])\n",
    "    merged_data = merged_data.drop(columns=['hour_t'])\n",
    "    merged_data = merged_data.drop(columns=['date'])\n",
    "\n",
    "    # 根据 hour 和 time_period 生成新的索引\n",
    "    index_mapping = {\n",
    "    (19, 0): 0, (19, 10): 1, (19, 20): 2, (19, 30): 3, (19, 40): 4, (19, 50): 5,\n",
    "    (20, 0): 6, (20, 10): 7, (20, 20): 8, (20, 30): 9, (20, 40): 10, (20, 50): 11, (21, 0): 12, (21, 10): 13, (21, 20): 14, (21, 30): 15, (21, 40): 16, (21, 50): 17, (22, 0): 18, (22, 10): 19, (22, 20): 20, (22, 30): 21, (22, 40): 22, (22, 50): 23, (23, 0): 24, (23, 10): 25, (23, 20): 26, (23, 30): 27, (23, 40): 28, (23, 50): 29, (0, 0): 30, (0, 10): 31, (0, 20): 32, (0, 30): 33, (0, 40): 34, (0, 50): 35}\n",
    "\n",
    "    # 应用索引映射\n",
    "    merged_data['index'] = merged_data.apply(lambda row: index_mapping.get((row['hour'], row['time_period']), -1), axis=1)\n",
    "\n",
    "\n",
    "    # 将索引列移动到第一列\n",
    "    merged_data = merged_data[['index'] + [col for col in merged_data.columns if col != 'index']]\n",
    "\n",
    "\n",
    "    # 丢弃不必要的列（如 'time_period_t' 列）\n",
    "    merged_data = merged_data.drop(columns=['hour'])\n",
    "    merged_data = merged_data.drop(columns=['time_period'])\n",
    "\n",
    "\n",
    "    # 保存处理后的数据\n",
    "    output_file_path = os.path.join(data_folder, f'processed_hourly_stats_level_{level}.csv')\n",
    "    merged_data.to_csv(output_file_path, index=False)\n",
    "    print(f'Processed data saved for level {level} to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据文件夹路径\n",
    "data_folder = './处理数据'\n",
    "\n",
    "# 假设你有 3 个等级\n",
    "levels = [0,1]  \n",
    "level_change_rate_data = {}\n",
    "\n",
    "for level in levels:\n",
    "    # 构建文件路径\n",
    "    file_path = os.path.join(data_folder, f'hourly_stats_level_{level}.csv')\n",
    "    \n",
    "    # 读取当前等级的数据\n",
    "    level_data = pd.read_csv(file_path)\n",
    "\n",
    "    # 你想要的小时顺序\n",
    "    desired_order = [19, 20, 21, 22, 23, 0]\n",
    "\n",
    "    # 将 hour 列转换为 Categorical 类型，并指定排序顺序\n",
    "    level_data['hour'] = pd.Categorical(level_data['hour'], categories=desired_order, ordered=True)\n",
    "\n",
    "    # 确保数据按照日期、小时和时间段排序\n",
    "    level_data = level_data.sort_values(by=['date', 'hour', 'time_period'])\n",
    "    \n",
    "    # 按照 'hour', 'time_period' 分组，计算 'real_time_user' 特征的平均值\n",
    "    avg_data = level_data.groupby(['hour', 'time_period'], observed=False)[['real_time_user']].mean().reset_index()\n",
    "\n",
    "    \n",
    "    # 计算变化率\n",
    "    avg_data['next_real_time_user'] = avg_data['real_time_user'].shift(-1)\n",
    "    avg_data['change_rate'] = (avg_data['next_real_time_user'] - avg_data['real_time_user']) / avg_data['real_time_user']\n",
    "    \n",
    "    # 处理时间跨小时的情况：当前的50分钟与下一小时的0分钟\n",
    "    for idx, row in avg_data.iterrows():\n",
    "        if row['time_period'] == 50:  # 如果是50分钟\n",
    "            # 找到下一行的时间是下一小时的0分钟的数据\n",
    "            next_index = idx + 1\n",
    "            if next_index < len(avg_data):\n",
    "                next_row = avg_data.iloc[next_index]\n",
    "                if next_row['hour'] == (row['hour'] + 1) % 24 and next_row['time_period'] == 0:\n",
    "                    avg_data.at[idx, 'change_rate'] = (\n",
    "                        next_row['real_time_user'] - row['real_time_user']\n",
    "                    ) / row['real_time_user']\n",
    "            else:\n",
    "                # 如果没有合适的下一行，则设置为NaN\n",
    "                avg_data.at[idx, 'change_rate'] = float('nan')\n",
    "    \n",
    "    # 删除不需要的列\n",
    "    avg_data = avg_data.drop(columns=['next_real_time_user'])\n",
    "\n",
    "    avg_data = avg_data.drop(columns=['hour'])\n",
    "    avg_data = avg_data.drop(columns=['time_period'])\n",
    "    avg_data = avg_data.drop(columns=['real_time_user'])\n",
    "\n",
    "    # 创建索引列\n",
    "    avg_data['index'] = avg_data.reset_index().index+1\n",
    "    \n",
    "    # 将索引列移动到第一列\n",
    "    avg_data = avg_data[['index'] + [col for col in avg_data.columns if col != 'index']]\n",
    "\n",
    "    \n",
    "    # 保存每个等级的变化率数据\n",
    "    output_file = os.path.join(data_folder, f'change_rate_real_time_user_level_{level}.csv')\n",
    "    avg_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved change rate data for level {level} to {output_file}')\n",
    "\n",
    "    # 将结果存储到字典中，以便后续使用\n",
    "    level_change_rate_data[level] = avg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ec6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义数据文件夹路径\n",
    "data_folder = './处理数据'\n",
    "\n",
    "# 假设你有 3 个等级\n",
    "levels = [0,1]  \n",
    "level_change_rate_data = {}\n",
    "\n",
    "for level in levels:\n",
    "    # 构建文件路径\n",
    "    file_path = os.path.join(data_folder, f'hourly_stats_level_{level}.csv')\n",
    "    \n",
    "    # 读取当前等级的数据\n",
    "    level_data = pd.read_csv(file_path)\n",
    "\n",
    "    # 你想要的小时顺序\n",
    "    desired_order = [19, 20, 21, 22, 23, 0]\n",
    "\n",
    "    # 将 hour 列转换为 Categorical 类型，并指定排序顺序\n",
    "    level_data['hour'] = pd.Categorical(level_data['hour'], categories=desired_order, ordered=True)\n",
    "\n",
    "    # 确保数据按照日期、小时和时间段排序\n",
    "    level_data = level_data.sort_values(by=['date', 'hour', 'time_period'])\n",
    "    \n",
    "    # 按照 'hour', 'time_period' 分组，计算 'real_time_user' 特征的平均值\n",
    "    avg_data = level_data.groupby(['hour', 'time_period'], observed=False)[['real_time_user']].mean().reset_index()\n",
    "\n",
    "    \n",
    "    # 计算变化率\n",
    "    avg_data['next_real_time_user'] = avg_data['real_time_user'].shift(-1)\n",
    "    avg_data['change_rate'] = (avg_data['next_real_time_user'] - avg_data['real_time_user']) / avg_data['real_time_user']\n",
    "    \n",
    "    # 处理时间跨小时的情况：当前的50分钟与下一小时的0分钟\n",
    "    for idx, row in avg_data.iterrows():\n",
    "        if row['time_period'] == 50:  # 如果是50分钟\n",
    "            # 找到下一行的时间是下一小时的0分钟的数据\n",
    "            next_index = idx + 1\n",
    "            if next_index < len(avg_data):\n",
    "                next_row = avg_data.iloc[next_index]\n",
    "                if next_row['hour'] == (row['hour'] + 1) % 24 and next_row['time_period'] == 0:\n",
    "                    avg_data.at[idx, 'change_rate'] = (\n",
    "                        next_row['real_time_user'] - row['real_time_user']\n",
    "                    ) / row['real_time_user']\n",
    "            else:\n",
    "                # 如果没有合适的下一行，则设置为NaN\n",
    "                avg_data.at[idx, 'change_rate'] = float('nan')\n",
    "    \n",
    "    # 删除不需要的列\n",
    "    # avg_data = avg_data.drop(columns=['next_real_time_user'])\n",
    "\n",
    "    # avg_data = avg_data.drop(columns=['hour'])\n",
    "    # avg_data = avg_data.drop(columns=['time_period'])\n",
    "    # avg_data = avg_data.drop(columns=['real_time_user'])\n",
    "\n",
    "    # 创建索引列\n",
    "    avg_data['index'] = avg_data.reset_index().index+1\n",
    "    \n",
    "    # 将索引列移动到第一列\n",
    "    avg_data = avg_data[['index'] + [col for col in avg_data.columns if col != 'index']]\n",
    "\n",
    "    \n",
    "    # 保存每个等级的变化率数据\n",
    "    output_file = os.path.join(data_folder, f'real_time_user_level_{level}.csv')\n",
    "    avg_data.to_csv(output_file, index=False)\n",
    "    print(f'Saved change rate data for level {level} to {output_file}')\n",
    "\n",
    "    # 将结果存储到字典中，以便后续使用\n",
    "    level_change_rate_data[level] = avg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164cee3e",
   "metadata": {},
   "source": [
    "# 5.描述结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd483a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras=pd.read_csv('best_parameters_and_thresholds_l1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e577132",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "paras.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc68ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0=pd.read_csv('window_accuracy_results_l0.csv')\n",
    "l1=pd.read_csv('window_accuracy_results_l1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cfb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "l0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8fee20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
